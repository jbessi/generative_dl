{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.5/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "87916544/87910968 [==============================] - 14s    \n"
     ]
    }
   ],
   "source": [
    "# loading pretrained inception V3 model for generating deep dream images\n",
    "\n",
    "import keras\n",
    "from keras.applications import inception_v3\n",
    "from keras import backend as K\n",
    "\n",
    "# We will not be training our model,\n",
    "# so we use this command to disable all training-specific operations\n",
    "K.set_learning_phase(0)\n",
    "\n",
    "# Build the InceptionV3 network.\n",
    "# The model will be loaded with pre-trained ImageNet weights.\n",
    "model = inception_v3.InceptionV3(weights='imagenet',\n",
    "                                 include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting the deepdream config, i.e. what layers should contribute to the final image\n",
    "# this is a somewhat arbitraty selection but can be changed and experimented with\n",
    "\n",
    "# Dict mapping layer names to a coefficient quantifying how much the layer's activation\n",
    "# will contribute to the loss we will seek to maximize.\n",
    "# Note that these are layer names as they appear in the built-in InceptionV3 application.\n",
    "# You can list all layer names using `model.summary()`.\n",
    "layer_contributions = {\n",
    "    'mixed2': 0.2,\n",
    "    'mixed3': 3.,\n",
    "    'mixed4': 2.,\n",
    "    'mixed5': 1.5,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_2 (InputLayer)             (None, None, None, 3) 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)               (None, None, None, 32 864         input_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNor (None, None, None, 32 96          conv2d_95[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_95 (Activation)       (None, None, None, 32 0           batch_normalization_95[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)               (None, None, None, 32 9216        activation_95[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNor (None, None, None, 32 96          conv2d_96[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_96 (Activation)       (None, None, None, 32 0           batch_normalization_96[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)               (None, None, None, 64 18432       activation_96[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNor (None, None, None, 64 192         conv2d_97[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_97 (Activation)       (None, None, None, 64 0           batch_normalization_97[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)   (None, None, None, 64 0           activation_97[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)               (None, None, None, 80 5120        max_pooling2d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNor (None, None, None, 80 240         conv2d_98[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_98 (Activation)       (None, None, None, 80 0           batch_normalization_98[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)               (None, None, None, 19 138240      activation_98[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_99 (BatchNor (None, None, None, 19 576         conv2d_99[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_99 (Activation)       (None, None, None, 19 0           batch_normalization_99[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)   (None, None, None, 19 0           activation_99[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)              (None, None, None, 64 12288       max_pooling2d_6[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_103 (BatchNo (None, None, None, 64 192         conv2d_103[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_103 (Activation)      (None, None, None, 64 0           batch_normalization_103[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)              (None, None, None, 48 9216        max_pooling2d_6[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)              (None, None, None, 96 55296       activation_103[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_101 (BatchNo (None, None, None, 48 144         conv2d_101[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_104 (BatchNo (None, None, None, 96 288         conv2d_104[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_101 (Activation)      (None, None, None, 48 0           batch_normalization_101[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_104 (Activation)      (None, None, None, 96 0           batch_normalization_104[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_10 (AveragePoo (None, None, None, 19 0           max_pooling2d_6[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)              (None, None, None, 64 12288       max_pooling2d_6[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)              (None, None, None, 64 76800       activation_101[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)              (None, None, None, 96 82944       activation_104[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_106 (Conv2D)              (None, None, None, 32 6144        average_pooling2d_10[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_100 (BatchNo (None, None, None, 64 192         conv2d_100[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_102 (BatchNo (None, None, None, 64 192         conv2d_102[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_105 (BatchNo (None, None, None, 96 288         conv2d_105[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_106 (BatchNo (None, None, None, 32 96          conv2d_106[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_100 (Activation)      (None, None, None, 64 0           batch_normalization_100[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_102 (Activation)      (None, None, None, 64 0           batch_normalization_102[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_105 (Activation)      (None, None, None, 96 0           batch_normalization_105[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_106 (Activation)      (None, None, None, 32 0           batch_normalization_106[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)             (None, None, None, 25 0           activation_100[0][0]             \n",
      "                                                                   activation_102[0][0]             \n",
      "                                                                   activation_105[0][0]             \n",
      "                                                                   activation_106[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_110 (Conv2D)              (None, None, None, 64 16384       mixed0[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_110 (BatchNo (None, None, None, 64 192         conv2d_110[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_110 (Activation)      (None, None, None, 64 0           batch_normalization_110[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_108 (Conv2D)              (None, None, None, 48 12288       mixed0[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_111 (Conv2D)              (None, None, None, 96 55296       activation_110[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_108 (BatchNo (None, None, None, 48 144         conv2d_108[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_111 (BatchNo (None, None, None, 96 288         conv2d_111[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_108 (Activation)      (None, None, None, 48 0           batch_normalization_108[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_111 (Activation)      (None, None, None, 96 0           batch_normalization_111[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_11 (AveragePoo (None, None, None, 25 0           mixed0[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_107 (Conv2D)              (None, None, None, 64 16384       mixed0[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_109 (Conv2D)              (None, None, None, 64 76800       activation_108[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_112 (Conv2D)              (None, None, None, 96 82944       activation_111[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_113 (Conv2D)              (None, None, None, 64 16384       average_pooling2d_11[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_107 (BatchNo (None, None, None, 64 192         conv2d_107[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_109 (BatchNo (None, None, None, 64 192         conv2d_109[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_112 (BatchNo (None, None, None, 96 288         conv2d_112[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_113 (BatchNo (None, None, None, 64 192         conv2d_113[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_107 (Activation)      (None, None, None, 64 0           batch_normalization_107[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_109 (Activation)      (None, None, None, 64 0           batch_normalization_109[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_112 (Activation)      (None, None, None, 96 0           batch_normalization_112[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_113 (Activation)      (None, None, None, 64 0           batch_normalization_113[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)             (None, None, None, 28 0           activation_107[0][0]             \n",
      "                                                                   activation_109[0][0]             \n",
      "                                                                   activation_112[0][0]             \n",
      "                                                                   activation_113[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_117 (Conv2D)              (None, None, None, 64 18432       mixed1[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_117 (BatchNo (None, None, None, 64 192         conv2d_117[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_117 (Activation)      (None, None, None, 64 0           batch_normalization_117[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_115 (Conv2D)              (None, None, None, 48 13824       mixed1[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_118 (Conv2D)              (None, None, None, 96 55296       activation_117[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_115 (BatchNo (None, None, None, 48 144         conv2d_115[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_118 (BatchNo (None, None, None, 96 288         conv2d_118[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_115 (Activation)      (None, None, None, 48 0           batch_normalization_115[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_118 (Activation)      (None, None, None, 96 0           batch_normalization_118[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_12 (AveragePoo (None, None, None, 28 0           mixed1[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_114 (Conv2D)              (None, None, None, 64 18432       mixed1[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_116 (Conv2D)              (None, None, None, 64 76800       activation_115[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_119 (Conv2D)              (None, None, None, 96 82944       activation_118[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_120 (Conv2D)              (None, None, None, 64 18432       average_pooling2d_12[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_114 (BatchNo (None, None, None, 64 192         conv2d_114[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_116 (BatchNo (None, None, None, 64 192         conv2d_116[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_119 (BatchNo (None, None, None, 96 288         conv2d_119[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_120 (BatchNo (None, None, None, 64 192         conv2d_120[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_114 (Activation)      (None, None, None, 64 0           batch_normalization_114[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_116 (Activation)      (None, None, None, 64 0           batch_normalization_116[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_119 (Activation)      (None, None, None, 96 0           batch_normalization_119[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_120 (Activation)      (None, None, None, 64 0           batch_normalization_120[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)             (None, None, None, 28 0           activation_114[0][0]             \n",
      "                                                                   activation_116[0][0]             \n",
      "                                                                   activation_119[0][0]             \n",
      "                                                                   activation_120[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_122 (Conv2D)              (None, None, None, 64 18432       mixed2[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_122 (BatchNo (None, None, None, 64 192         conv2d_122[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_122 (Activation)      (None, None, None, 64 0           batch_normalization_122[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_123 (Conv2D)              (None, None, None, 96 55296       activation_122[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_123 (BatchNo (None, None, None, 96 288         conv2d_123[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_123 (Activation)      (None, None, None, 96 0           batch_normalization_123[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_121 (Conv2D)              (None, None, None, 38 995328      mixed2[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_124 (Conv2D)              (None, None, None, 96 82944       activation_123[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_121 (BatchNo (None, None, None, 38 1152        conv2d_121[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_124 (BatchNo (None, None, None, 96 288         conv2d_124[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_121 (Activation)      (None, None, None, 38 0           batch_normalization_121[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_124 (Activation)      (None, None, None, 96 0           batch_normalization_124[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)   (None, None, None, 28 0           mixed2[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)             (None, None, None, 76 0           activation_121[0][0]             \n",
      "                                                                   activation_124[0][0]             \n",
      "                                                                   max_pooling2d_7[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_129 (Conv2D)              (None, None, None, 12 98304       mixed3[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_129 (BatchNo (None, None, None, 12 384         conv2d_129[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_129 (Activation)      (None, None, None, 12 0           batch_normalization_129[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_130 (Conv2D)              (None, None, None, 12 114688      activation_129[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_130 (BatchNo (None, None, None, 12 384         conv2d_130[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_130 (Activation)      (None, None, None, 12 0           batch_normalization_130[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_126 (Conv2D)              (None, None, None, 12 98304       mixed3[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_131 (Conv2D)              (None, None, None, 12 114688      activation_130[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_126 (BatchNo (None, None, None, 12 384         conv2d_126[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_131 (BatchNo (None, None, None, 12 384         conv2d_131[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_126 (Activation)      (None, None, None, 12 0           batch_normalization_126[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_131 (Activation)      (None, None, None, 12 0           batch_normalization_131[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_127 (Conv2D)              (None, None, None, 12 114688      activation_126[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_132 (Conv2D)              (None, None, None, 12 114688      activation_131[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_127 (BatchNo (None, None, None, 12 384         conv2d_127[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_132 (BatchNo (None, None, None, 12 384         conv2d_132[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_127 (Activation)      (None, None, None, 12 0           batch_normalization_127[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_132 (Activation)      (None, None, None, 12 0           batch_normalization_132[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_13 (AveragePoo (None, None, None, 76 0           mixed3[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_125 (Conv2D)              (None, None, None, 19 147456      mixed3[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_128 (Conv2D)              (None, None, None, 19 172032      activation_127[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_133 (Conv2D)              (None, None, None, 19 172032      activation_132[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_134 (Conv2D)              (None, None, None, 19 147456      average_pooling2d_13[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_125 (BatchNo (None, None, None, 19 576         conv2d_125[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_128 (BatchNo (None, None, None, 19 576         conv2d_128[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_133 (BatchNo (None, None, None, 19 576         conv2d_133[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_134 (BatchNo (None, None, None, 19 576         conv2d_134[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_125 (Activation)      (None, None, None, 19 0           batch_normalization_125[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_128 (Activation)      (None, None, None, 19 0           batch_normalization_128[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_133 (Activation)      (None, None, None, 19 0           batch_normalization_133[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_134 (Activation)      (None, None, None, 19 0           batch_normalization_134[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)             (None, None, None, 76 0           activation_125[0][0]             \n",
      "                                                                   activation_128[0][0]             \n",
      "                                                                   activation_133[0][0]             \n",
      "                                                                   activation_134[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_139 (Conv2D)              (None, None, None, 16 122880      mixed4[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_139 (BatchNo (None, None, None, 16 480         conv2d_139[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_139 (Activation)      (None, None, None, 16 0           batch_normalization_139[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_140 (Conv2D)              (None, None, None, 16 179200      activation_139[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_140 (BatchNo (None, None, None, 16 480         conv2d_140[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_140 (Activation)      (None, None, None, 16 0           batch_normalization_140[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_136 (Conv2D)              (None, None, None, 16 122880      mixed4[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_141 (Conv2D)              (None, None, None, 16 179200      activation_140[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_136 (BatchNo (None, None, None, 16 480         conv2d_136[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_141 (BatchNo (None, None, None, 16 480         conv2d_141[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_136 (Activation)      (None, None, None, 16 0           batch_normalization_136[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_141 (Activation)      (None, None, None, 16 0           batch_normalization_141[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_137 (Conv2D)              (None, None, None, 16 179200      activation_136[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_142 (Conv2D)              (None, None, None, 16 179200      activation_141[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_137 (BatchNo (None, None, None, 16 480         conv2d_137[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_142 (BatchNo (None, None, None, 16 480         conv2d_142[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_137 (Activation)      (None, None, None, 16 0           batch_normalization_137[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_142 (Activation)      (None, None, None, 16 0           batch_normalization_142[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_14 (AveragePoo (None, None, None, 76 0           mixed4[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_135 (Conv2D)              (None, None, None, 19 147456      mixed4[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_138 (Conv2D)              (None, None, None, 19 215040      activation_137[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_143 (Conv2D)              (None, None, None, 19 215040      activation_142[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_144 (Conv2D)              (None, None, None, 19 147456      average_pooling2d_14[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_135 (BatchNo (None, None, None, 19 576         conv2d_135[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_138 (BatchNo (None, None, None, 19 576         conv2d_138[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_143 (BatchNo (None, None, None, 19 576         conv2d_143[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_144 (BatchNo (None, None, None, 19 576         conv2d_144[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_135 (Activation)      (None, None, None, 19 0           batch_normalization_135[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_138 (Activation)      (None, None, None, 19 0           batch_normalization_138[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_143 (Activation)      (None, None, None, 19 0           batch_normalization_143[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_144 (Activation)      (None, None, None, 19 0           batch_normalization_144[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)             (None, None, None, 76 0           activation_135[0][0]             \n",
      "                                                                   activation_138[0][0]             \n",
      "                                                                   activation_143[0][0]             \n",
      "                                                                   activation_144[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_149 (Conv2D)              (None, None, None, 16 122880      mixed5[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_149 (BatchNo (None, None, None, 16 480         conv2d_149[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_149 (Activation)      (None, None, None, 16 0           batch_normalization_149[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_150 (Conv2D)              (None, None, None, 16 179200      activation_149[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_150 (BatchNo (None, None, None, 16 480         conv2d_150[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_150 (Activation)      (None, None, None, 16 0           batch_normalization_150[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_146 (Conv2D)              (None, None, None, 16 122880      mixed5[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_151 (Conv2D)              (None, None, None, 16 179200      activation_150[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_146 (BatchNo (None, None, None, 16 480         conv2d_146[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_151 (BatchNo (None, None, None, 16 480         conv2d_151[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_146 (Activation)      (None, None, None, 16 0           batch_normalization_146[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_151 (Activation)      (None, None, None, 16 0           batch_normalization_151[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_147 (Conv2D)              (None, None, None, 16 179200      activation_146[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_152 (Conv2D)              (None, None, None, 16 179200      activation_151[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_147 (BatchNo (None, None, None, 16 480         conv2d_147[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_152 (BatchNo (None, None, None, 16 480         conv2d_152[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_147 (Activation)      (None, None, None, 16 0           batch_normalization_147[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_152 (Activation)      (None, None, None, 16 0           batch_normalization_152[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_15 (AveragePoo (None, None, None, 76 0           mixed5[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_145 (Conv2D)              (None, None, None, 19 147456      mixed5[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_148 (Conv2D)              (None, None, None, 19 215040      activation_147[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_153 (Conv2D)              (None, None, None, 19 215040      activation_152[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_154 (Conv2D)              (None, None, None, 19 147456      average_pooling2d_15[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_145 (BatchNo (None, None, None, 19 576         conv2d_145[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_148 (BatchNo (None, None, None, 19 576         conv2d_148[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_153 (BatchNo (None, None, None, 19 576         conv2d_153[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_154 (BatchNo (None, None, None, 19 576         conv2d_154[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_145 (Activation)      (None, None, None, 19 0           batch_normalization_145[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_148 (Activation)      (None, None, None, 19 0           batch_normalization_148[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_153 (Activation)      (None, None, None, 19 0           batch_normalization_153[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_154 (Activation)      (None, None, None, 19 0           batch_normalization_154[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)             (None, None, None, 76 0           activation_145[0][0]             \n",
      "                                                                   activation_148[0][0]             \n",
      "                                                                   activation_153[0][0]             \n",
      "                                                                   activation_154[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_159 (Conv2D)              (None, None, None, 19 147456      mixed6[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_159 (BatchNo (None, None, None, 19 576         conv2d_159[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_159 (Activation)      (None, None, None, 19 0           batch_normalization_159[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_160 (Conv2D)              (None, None, None, 19 258048      activation_159[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_160 (BatchNo (None, None, None, 19 576         conv2d_160[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_160 (Activation)      (None, None, None, 19 0           batch_normalization_160[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_156 (Conv2D)              (None, None, None, 19 147456      mixed6[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_161 (Conv2D)              (None, None, None, 19 258048      activation_160[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_156 (BatchNo (None, None, None, 19 576         conv2d_156[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_161 (BatchNo (None, None, None, 19 576         conv2d_161[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_156 (Activation)      (None, None, None, 19 0           batch_normalization_156[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_161 (Activation)      (None, None, None, 19 0           batch_normalization_161[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_157 (Conv2D)              (None, None, None, 19 258048      activation_156[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_162 (Conv2D)              (None, None, None, 19 258048      activation_161[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_157 (BatchNo (None, None, None, 19 576         conv2d_157[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_162 (BatchNo (None, None, None, 19 576         conv2d_162[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_157 (Activation)      (None, None, None, 19 0           batch_normalization_157[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_162 (Activation)      (None, None, None, 19 0           batch_normalization_162[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_16 (AveragePoo (None, None, None, 76 0           mixed6[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_155 (Conv2D)              (None, None, None, 19 147456      mixed6[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_158 (Conv2D)              (None, None, None, 19 258048      activation_157[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_163 (Conv2D)              (None, None, None, 19 258048      activation_162[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_164 (Conv2D)              (None, None, None, 19 147456      average_pooling2d_16[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_155 (BatchNo (None, None, None, 19 576         conv2d_155[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_158 (BatchNo (None, None, None, 19 576         conv2d_158[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_163 (BatchNo (None, None, None, 19 576         conv2d_163[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_164 (BatchNo (None, None, None, 19 576         conv2d_164[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_155 (Activation)      (None, None, None, 19 0           batch_normalization_155[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_158 (Activation)      (None, None, None, 19 0           batch_normalization_158[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_163 (Activation)      (None, None, None, 19 0           batch_normalization_163[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_164 (Activation)      (None, None, None, 19 0           batch_normalization_164[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)             (None, None, None, 76 0           activation_155[0][0]             \n",
      "                                                                   activation_158[0][0]             \n",
      "                                                                   activation_163[0][0]             \n",
      "                                                                   activation_164[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_167 (Conv2D)              (None, None, None, 19 147456      mixed7[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_167 (BatchNo (None, None, None, 19 576         conv2d_167[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_167 (Activation)      (None, None, None, 19 0           batch_normalization_167[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_168 (Conv2D)              (None, None, None, 19 258048      activation_167[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_168 (BatchNo (None, None, None, 19 576         conv2d_168[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_168 (Activation)      (None, None, None, 19 0           batch_normalization_168[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_165 (Conv2D)              (None, None, None, 19 147456      mixed7[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_169 (Conv2D)              (None, None, None, 19 258048      activation_168[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_165 (BatchNo (None, None, None, 19 576         conv2d_165[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_169 (BatchNo (None, None, None, 19 576         conv2d_169[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_165 (Activation)      (None, None, None, 19 0           batch_normalization_165[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_169 (Activation)      (None, None, None, 19 0           batch_normalization_169[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_166 (Conv2D)              (None, None, None, 32 552960      activation_165[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_170 (Conv2D)              (None, None, None, 19 331776      activation_169[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_166 (BatchNo (None, None, None, 32 960         conv2d_166[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_170 (BatchNo (None, None, None, 19 576         conv2d_170[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_166 (Activation)      (None, None, None, 32 0           batch_normalization_166[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_170 (Activation)      (None, None, None, 19 0           batch_normalization_170[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)   (None, None, None, 76 0           mixed7[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)             (None, None, None, 12 0           activation_166[0][0]             \n",
      "                                                                   activation_170[0][0]             \n",
      "                                                                   max_pooling2d_8[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_175 (Conv2D)              (None, None, None, 44 573440      mixed8[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_175 (BatchNo (None, None, None, 44 1344        conv2d_175[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_175 (Activation)      (None, None, None, 44 0           batch_normalization_175[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_172 (Conv2D)              (None, None, None, 38 491520      mixed8[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_176 (Conv2D)              (None, None, None, 38 1548288     activation_175[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_172 (BatchNo (None, None, None, 38 1152        conv2d_172[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_176 (BatchNo (None, None, None, 38 1152        conv2d_176[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_172 (Activation)      (None, None, None, 38 0           batch_normalization_172[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_176 (Activation)      (None, None, None, 38 0           batch_normalization_176[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_173 (Conv2D)              (None, None, None, 38 442368      activation_172[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_174 (Conv2D)              (None, None, None, 38 442368      activation_172[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_177 (Conv2D)              (None, None, None, 38 442368      activation_176[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_178 (Conv2D)              (None, None, None, 38 442368      activation_176[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_17 (AveragePoo (None, None, None, 12 0           mixed8[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_171 (Conv2D)              (None, None, None, 32 409600      mixed8[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_173 (BatchNo (None, None, None, 38 1152        conv2d_173[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_174 (BatchNo (None, None, None, 38 1152        conv2d_174[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_177 (BatchNo (None, None, None, 38 1152        conv2d_177[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_178 (BatchNo (None, None, None, 38 1152        conv2d_178[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_179 (Conv2D)              (None, None, None, 19 245760      average_pooling2d_17[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_171 (BatchNo (None, None, None, 32 960         conv2d_171[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_173 (Activation)      (None, None, None, 38 0           batch_normalization_173[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_174 (Activation)      (None, None, None, 38 0           batch_normalization_174[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_177 (Activation)      (None, None, None, 38 0           batch_normalization_177[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_178 (Activation)      (None, None, None, 38 0           batch_normalization_178[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_179 (BatchNo (None, None, None, 19 576         conv2d_179[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_171 (Activation)      (None, None, None, 32 0           batch_normalization_171[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)           (None, None, None, 76 0           activation_173[0][0]             \n",
      "                                                                   activation_174[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)      (None, None, None, 76 0           activation_177[0][0]             \n",
      "                                                                   activation_178[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_179 (Activation)      (None, None, None, 19 0           batch_normalization_179[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)             (None, None, None, 20 0           activation_171[0][0]             \n",
      "                                                                   mixed9_0[0][0]                   \n",
      "                                                                   concatenate_3[0][0]              \n",
      "                                                                   activation_179[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_184 (Conv2D)              (None, None, None, 44 917504      mixed9[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_184 (BatchNo (None, None, None, 44 1344        conv2d_184[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_184 (Activation)      (None, None, None, 44 0           batch_normalization_184[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_181 (Conv2D)              (None, None, None, 38 786432      mixed9[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_185 (Conv2D)              (None, None, None, 38 1548288     activation_184[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_181 (BatchNo (None, None, None, 38 1152        conv2d_181[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_185 (BatchNo (None, None, None, 38 1152        conv2d_185[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_181 (Activation)      (None, None, None, 38 0           batch_normalization_181[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_185 (Activation)      (None, None, None, 38 0           batch_normalization_185[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_182 (Conv2D)              (None, None, None, 38 442368      activation_181[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_183 (Conv2D)              (None, None, None, 38 442368      activation_181[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_186 (Conv2D)              (None, None, None, 38 442368      activation_185[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_187 (Conv2D)              (None, None, None, 38 442368      activation_185[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_18 (AveragePoo (None, None, None, 20 0           mixed9[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_180 (Conv2D)              (None, None, None, 32 655360      mixed9[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_182 (BatchNo (None, None, None, 38 1152        conv2d_182[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_183 (BatchNo (None, None, None, 38 1152        conv2d_183[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_186 (BatchNo (None, None, None, 38 1152        conv2d_186[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_187 (BatchNo (None, None, None, 38 1152        conv2d_187[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_188 (Conv2D)              (None, None, None, 19 393216      average_pooling2d_18[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_180 (BatchNo (None, None, None, 32 960         conv2d_180[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_182 (Activation)      (None, None, None, 38 0           batch_normalization_182[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_183 (Activation)      (None, None, None, 38 0           batch_normalization_183[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_186 (Activation)      (None, None, None, 38 0           batch_normalization_186[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_187 (Activation)      (None, None, None, 38 0           batch_normalization_187[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_188 (BatchNo (None, None, None, 19 576         conv2d_188[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_180 (Activation)      (None, None, None, 32 0           batch_normalization_180[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)           (None, None, None, 76 0           activation_182[0][0]             \n",
      "                                                                   activation_183[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)      (None, None, None, 76 0           activation_186[0][0]             \n",
      "                                                                   activation_187[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_188 (Activation)      (None, None, None, 19 0           batch_normalization_188[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)            (None, None, None, 20 0           activation_180[0][0]             \n",
      "                                                                   mixed9_1[0][0]                   \n",
      "                                                                   concatenate_4[0][0]              \n",
      "                                                                   activation_188[0][0]             \n",
      "====================================================================================================\n",
      "Total params: 21,802,784\n",
      "Trainable params: 21,768,352\n",
      "Non-trainable params: 34,432\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/joel/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:1205: calling reduce_prod_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /home/joel/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:1188: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:Variable += will be deprecated. Use variable.assign_add if you want assignment to the variable value or 'x = x + y' if you want a new python Tensor object.\n"
     ]
    }
   ],
   "source": [
    "# defininig a loss by the weighted sum of L2 norm of the activations of the layers defined above\n",
    "\n",
    "# Get the symbolic outputs of each \"key\" layer (we gave them unique names).\n",
    "layer_dict = dict([(layer.name, layer) for layer in model.layers])\n",
    "\n",
    "# Define the loss.\n",
    "loss = K.variable(0.) #instantiating a variable with value 0\n",
    "for layer_name in layer_contributions:\n",
    "    # Add the L2 norm of the features of a layer to the loss.\n",
    "    coeff = layer_contributions[layer_name]\n",
    "    activation = layer_dict[layer_name].output\n",
    "    # We avoid border artifacts by only involving non-border pixels in the loss.\n",
    "    scaling = K.prod(K.cast(K.shape(activation), 'float32'))\n",
    "    loss += coeff * K.sum(K.square(activation[:, 2: -2, 2: -2, :])) / scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_2': <keras.engine.topology.InputLayer at 0x7fac0037e5f8>,\n",
       " 'conv2d_95': <keras.layers.convolutional.Conv2D at 0x7fac0037e940>,\n",
       " 'batch_normalization_95': <keras.layers.normalization.BatchNormalization at 0x7fac0037e7b8>,\n",
       " 'activation_95': <keras.layers.core.Activation at 0x7fac0038d2e8>,\n",
       " 'conv2d_96': <keras.layers.convolutional.Conv2D at 0x7fac0038d9b0>,\n",
       " 'batch_normalization_96': <keras.layers.normalization.BatchNormalization at 0x7fac0037ecf8>,\n",
       " 'activation_96': <keras.layers.core.Activation at 0x7fac003a5780>,\n",
       " 'conv2d_97': <keras.layers.convolutional.Conv2D at 0x7fac003a5b70>,\n",
       " 'batch_normalization_97': <keras.layers.normalization.BatchNormalization at 0x7fac002fe898>,\n",
       " 'activation_97': <keras.layers.core.Activation at 0x7fac00313b38>,\n",
       " 'max_pooling2d_5': <keras.layers.pooling.MaxPooling2D at 0x7fac00313c18>,\n",
       " 'conv2d_98': <keras.layers.convolutional.Conv2D at 0x7fac002cbc88>,\n",
       " 'batch_normalization_98': <keras.layers.normalization.BatchNormalization at 0x7fac002832b0>,\n",
       " 'activation_98': <keras.layers.core.Activation at 0x7fac0026de80>,\n",
       " 'conv2d_99': <keras.layers.convolutional.Conv2D at 0x7fac00239f60>,\n",
       " 'batch_normalization_99': <keras.layers.normalization.BatchNormalization at 0x7fac00258ac8>,\n",
       " 'activation_99': <keras.layers.core.Activation at 0x7fac001eedd8>,\n",
       " 'max_pooling2d_6': <keras.layers.pooling.MaxPooling2D at 0x7fac00239cc0>,\n",
       " 'conv2d_103': <keras.layers.convolutional.Conv2D at 0x7fac000d9550>,\n",
       " 'batch_normalization_103': <keras.layers.normalization.BatchNormalization at 0x7fac00095da0>,\n",
       " 'activation_103': <keras.layers.core.Activation at 0x7fac00045128>,\n",
       " 'conv2d_101': <keras.layers.convolutional.Conv2D at 0x7fac00198e80>,\n",
       " 'conv2d_104': <keras.layers.convolutional.Conv2D at 0x7fac000455f8>,\n",
       " 'batch_normalization_101': <keras.layers.normalization.BatchNormalization at 0x7fac001380b8>,\n",
       " 'batch_normalization_104': <keras.layers.normalization.BatchNormalization at 0x7fabfbfd7c50>,\n",
       " 'activation_101': <keras.layers.core.Activation at 0x7fac00167198>,\n",
       " 'activation_104': <keras.layers.core.Activation at 0x7fabfbfa5b00>,\n",
       " 'average_pooling2d_10': <keras.layers.pooling.AveragePooling2D at 0x7fabfbf775f8>,\n",
       " 'conv2d_100': <keras.layers.convolutional.Conv2D at 0x7fac001c9400>,\n",
       " 'conv2d_102': <keras.layers.convolutional.Conv2D at 0x7fac00167668>,\n",
       " 'conv2d_105': <keras.layers.convolutional.Conv2D at 0x7fabfbfee550>,\n",
       " 'conv2d_106': <keras.layers.convolutional.Conv2D at 0x7fabfbf36828>,\n",
       " 'batch_normalization_100': <keras.layers.normalization.BatchNormalization at 0x7fac001dd128>,\n",
       " 'batch_normalization_102': <keras.layers.normalization.BatchNormalization at 0x7fac00125be0>,\n",
       " 'batch_normalization_105': <keras.layers.normalization.BatchNormalization at 0x7fabfbf49cc0>,\n",
       " 'batch_normalization_106': <keras.layers.normalization.BatchNormalization at 0x7fabfbecb3c8>,\n",
       " 'activation_100': <keras.layers.core.Activation at 0x7fac00258a20>,\n",
       " 'activation_102': <keras.layers.core.Activation at 0x7fac00076b38>,\n",
       " 'activation_105': <keras.layers.core.Activation at 0x7fabfbf17ba8>,\n",
       " 'activation_106': <keras.layers.core.Activation at 0x7fabfbe836d8>,\n",
       " 'mixed0': <keras.layers.merge.Concatenate at 0x7fabfbee7860>,\n",
       " 'conv2d_110': <keras.layers.convolutional.Conv2D at 0x7fabfbdafeb8>,\n",
       " 'batch_normalization_110': <keras.layers.normalization.BatchNormalization at 0x7fabfbd6ad68>,\n",
       " 'activation_110': <keras.layers.core.Activation at 0x7fabfbd1eeb8>,\n",
       " 'conv2d_108': <keras.layers.convolutional.Conv2D at 0x7fabfbe54a90>,\n",
       " 'conv2d_111': <keras.layers.convolutional.Conv2D at 0x7fabfbd7ef60>,\n",
       " 'batch_normalization_108': <keras.layers.normalization.BatchNormalization at 0x7fabfbe2dd68>,\n",
       " 'batch_normalization_111': <keras.layers.normalization.BatchNormalization at 0x7fabfbcdacc0>,\n",
       " 'activation_108': <keras.layers.core.Activation at 0x7fabfbddfeb8>,\n",
       " 'activation_111': <keras.layers.core.Activation at 0x7fabfbcef6d8>,\n",
       " 'average_pooling2d_11': <keras.layers.pooling.AveragePooling2D at 0x7fabfbc5bf60>,\n",
       " 'conv2d_107': <keras.layers.convolutional.Conv2D at 0x7fabfbea60b8>,\n",
       " 'conv2d_109': <keras.layers.convolutional.Conv2D at 0x7fabfbdc0f60>,\n",
       " 'conv2d_112': <keras.layers.convolutional.Conv2D at 0x7fabfbcefeb8>,\n",
       " 'conv2d_113': <keras.layers.convolutional.Conv2D at 0x7fabfbc18e10>,\n",
       " 'batch_normalization_107': <keras.layers.normalization.BatchNormalization at 0x7fabfbebb0b8>,\n",
       " 'batch_normalization_109': <keras.layers.normalization.BatchNormalization at 0x7fabfbd9bcc0>,\n",
       " 'batch_normalization_112': <keras.layers.normalization.BatchNormalization at 0x7fabfbc48d68>,\n",
       " 'batch_normalization_113': <keras.layers.normalization.BatchNormalization at 0x7fabfbc38438>,\n",
       " 'activation_107': <keras.layers.core.Activation at 0x7fabfbe547b8>,\n",
       " 'activation_109': <keras.layers.core.Activation at 0x7fabfbdaf6a0>,\n",
       " 'activation_112': <keras.layers.core.Activation at 0x7fabfbc5b780>,\n",
       " 'activation_113': <keras.layers.core.Activation at 0x7fabfbbec828>,\n",
       " 'mixed1': <keras.layers.merge.Concatenate at 0x7fabfbbcc710>,\n",
       " 'conv2d_117': <keras.layers.convolutional.Conv2D at 0x7fabfbae4550>,\n",
       " 'batch_normalization_117': <keras.layers.normalization.BatchNormalization at 0x7fabfba75a20>,\n",
       " 'activation_117': <keras.layers.core.Activation at 0x7fabfba24ef0>,\n",
       " 'conv2d_115': <keras.layers.convolutional.Conv2D at 0x7fabfbbbc940>,\n",
       " 'conv2d_118': <keras.layers.convolutional.Conv2D at 0x7fabfba0bcf8>,\n",
       " 'batch_normalization_115': <keras.layers.normalization.BatchNormalization at 0x7fabfbb15a20>,\n",
       " 'batch_normalization_118': <keras.layers.normalization.BatchNormalization at 0x7fabfb9e7978>,\n",
       " 'activation_115': <keras.layers.core.Activation at 0x7fabfbac4ef0>,\n",
       " 'activation_118': <keras.layers.core.Activation at 0x7fabfb9fac50>,\n",
       " 'average_pooling2d_12': <keras.layers.pooling.AveragePooling2D at 0x7fabfb9b1da0>,\n",
       " 'conv2d_114': <keras.layers.convolutional.Conv2D at 0x7fabfbb89a58>,\n",
       " 'conv2d_116': <keras.layers.convolutional.Conv2D at 0x7fabfbb2bcf8>,\n",
       " 'conv2d_119': <keras.layers.convolutional.Conv2D at 0x7fabfb9fac88>,\n",
       " 'conv2d_120': <keras.layers.convolutional.Conv2D at 0x7fabfb8c0390>,\n",
       " 'batch_normalization_114': <keras.layers.normalization.BatchNormalization at 0x7fabfbba6748>,\n",
       " 'batch_normalization_116': <keras.layers.normalization.BatchNormalization at 0x7fabfba87978>,\n",
       " 'batch_normalization_119': <keras.layers.normalization.BatchNormalization at 0x7fabfb953a90>,\n",
       " 'batch_normalization_120': <keras.layers.normalization.BatchNormalization at 0x7fabfb8d8160>,\n",
       " 'activation_114': <keras.layers.core.Activation at 0x7fabfbbbc978>,\n",
       " 'activation_116': <keras.layers.core.Activation at 0x7fabfba9dc88>,\n",
       " 'activation_119': <keras.layers.core.Activation at 0x7fabfb96bd30>,\n",
       " 'activation_120': <keras.layers.core.Activation at 0x7fabfb890eb8>,\n",
       " 'mixed2': <keras.layers.merge.Concatenate at 0x7fabfb8ef550>,\n",
       " 'conv2d_122': <keras.layers.convolutional.Conv2D at 0x7fabfb85e780>,\n",
       " 'batch_normalization_122': <keras.layers.normalization.BatchNormalization at 0x7fabfb81da90>,\n",
       " 'activation_122': <keras.layers.core.Activation at 0x7fabfb7cd470>,\n",
       " 'conv2d_123': <keras.layers.convolutional.Conv2D at 0x7fabfb7cd940>,\n",
       " 'batch_normalization_123': <keras.layers.normalization.BatchNormalization at 0x7fabfb7ebba8>,\n",
       " 'activation_123': <keras.layers.core.Activation at 0x7fabfb75be80>,\n",
       " 'conv2d_121': <keras.layers.convolutional.Conv2D at 0x7fabfb8b1cc0>,\n",
       " 'conv2d_124': <keras.layers.convolutional.Conv2D at 0x7fabfb7bd898>,\n",
       " 'batch_normalization_121': <keras.layers.normalization.BatchNormalization at 0x7fabfb8b1710>,\n",
       " 'batch_normalization_124': <keras.layers.normalization.BatchNormalization at 0x7fabfb778a90>,\n",
       " 'activation_121': <keras.layers.core.Activation at 0x7fabfb87e5f8>,\n",
       " 'activation_124': <keras.layers.core.Activation at 0x7fabfb6caef0>,\n",
       " 'max_pooling2d_7': <keras.layers.pooling.MaxPooling2D at 0x7fabfb72b3c8>,\n",
       " 'mixed3': <keras.layers.merge.Concatenate at 0x7fabfb6e6b70>,\n",
       " 'conv2d_129': <keras.layers.convolutional.Conv2D at 0x7fabfb563908>,\n",
       " 'batch_normalization_129': <keras.layers.normalization.BatchNormalization at 0x7fabfb4c0eb8>,\n",
       " 'activation_129': <keras.layers.core.Activation at 0x7fabfb4f2a90>,\n",
       " 'conv2d_130': <keras.layers.convolutional.Conv2D at 0x7fabfb4d59b0>,\n",
       " 'batch_normalization_130': <keras.layers.normalization.BatchNormalization at 0x7fabfb4aff98>,\n",
       " 'activation_130': <keras.layers.core.Activation at 0x7fabfb445a58>,\n",
       " 'conv2d_126': <keras.layers.convolutional.Conv2D at 0x7fabfb6b8f98>,\n",
       " 'conv2d_131': <keras.layers.convolutional.Conv2D at 0x7fabfb445908>,\n",
       " 'batch_normalization_126': <keras.layers.normalization.BatchNormalization at 0x7fabfb675f98>,\n",
       " 'batch_normalization_131': <keras.layers.normalization.BatchNormalization at 0x7fabfb41feb8>,\n",
       " 'activation_126': <keras.layers.core.Activation at 0x7fabfb6289e8>,\n",
       " 'activation_131': <keras.layers.core.Activation at 0x7fabfb433b00>,\n",
       " 'conv2d_127': <keras.layers.convolutional.Conv2D at 0x7fabfb607908>,\n",
       " 'conv2d_132': <keras.layers.convolutional.Conv2D at 0x7fabfb4339b0>,\n",
       " 'batch_normalization_127': <keras.layers.normalization.BatchNormalization at 0x7fabfb5e3f28>,\n",
       " 'batch_normalization_132': <keras.layers.normalization.BatchNormalization at 0x7fabfb38ef60>,\n",
       " 'activation_127': <keras.layers.core.Activation at 0x7fabfb5f9828>,\n",
       " 'activation_132': <keras.layers.core.Activation at 0x7fabfb3a4a58>,\n",
       " 'average_pooling2d_13': <keras.layers.pooling.AveragePooling2D at 0x7fabfb312be0>,\n",
       " 'conv2d_125': <keras.layers.convolutional.Conv2D at 0x7fabfb684358>,\n",
       " 'conv2d_128': <keras.layers.convolutional.Conv2D at 0x7fabfb5f9940>,\n",
       " 'conv2d_133': <keras.layers.convolutional.Conv2D at 0x7fabfb3a4b38>,\n",
       " 'conv2d_134': <keras.layers.convolutional.Conv2D at 0x7fabfb2ea2b0>,\n",
       " 'batch_normalization_125': <keras.layers.normalization.BatchNormalization at 0x7fabfb69eba8>,\n",
       " 'batch_normalization_128': <keras.layers.normalization.BatchNormalization at 0x7fabfb54ff98>,\n",
       " 'batch_normalization_133': <keras.layers.normalization.BatchNormalization at 0x7fabfb35ebe0>,\n",
       " 'batch_normalization_134': <keras.layers.normalization.BatchNormalization at 0x7fabfb282c88>,\n",
       " 'activation_125': <keras.layers.core.Activation at 0x7fabfb6b87f0>,\n",
       " 'activation_128': <keras.layers.core.Activation at 0x7fabfb563a58>,\n",
       " 'activation_133': <keras.layers.core.Activation at 0x7fabfb312b00>,\n",
       " 'activation_134': <keras.layers.core.Activation at 0x7fabfb29df98>,\n",
       " 'mixed4': <keras.layers.merge.Concatenate at 0x7fabfb29d198>,\n",
       " 'conv2d_139': <keras.layers.convolutional.Conv2D at 0x7fabfb0d6748>,\n",
       " 'batch_normalization_139': <keras.layers.normalization.BatchNormalization at 0x7fabfb095908>,\n",
       " 'activation_139': <keras.layers.core.Activation at 0x7fabfb004748>,\n",
       " 'conv2d_140': <keras.layers.convolutional.Conv2D at 0x7fabfb044320>,\n",
       " 'batch_normalization_140': <keras.layers.normalization.BatchNormalization at 0x7fabfb0447f0>,\n",
       " 'activation_140': <keras.layers.core.Activation at 0x7fabfafd4d30>,\n",
       " 'conv2d_136': <keras.layers.convolutional.Conv2D at 0x7fabfb20b588>,\n",
       " 'conv2d_141': <keras.layers.convolutional.Conv2D at 0x7fabfb035748>,\n",
       " 'batch_normalization_136': <keras.layers.normalization.BatchNormalization at 0x7fabfb1ca898>,\n",
       " 'batch_normalization_141': <keras.layers.normalization.BatchNormalization at 0x7fabfaff5940>,\n",
       " 'activation_136': <keras.layers.core.Activation at 0x7fabfb1b56a0>,\n",
       " 'activation_141': <keras.layers.core.Activation at 0x7fabfaf45da0>,\n",
       " 'conv2d_137': <keras.layers.convolutional.Conv2D at 0x7fabfb1f3278>,\n",
       " 'conv2d_142': <keras.layers.convolutional.Conv2D at 0x7fabfafa47b8>,\n",
       " 'batch_normalization_137': <keras.layers.normalization.BatchNormalization at 0x7fabfb1f3748>,\n",
       " 'batch_normalization_142': <keras.layers.normalization.BatchNormalization at 0x7fabfaf629b0>,\n",
       " 'activation_137': <keras.layers.core.Activation at 0x7fabfb109c88>,\n",
       " 'activation_142': <keras.layers.core.Activation at 0x7fabfaf32e80>,\n",
       " 'average_pooling2d_14': <keras.layers.pooling.AveragePooling2D at 0x7fabfae83940>,\n",
       " 'conv2d_135': <keras.layers.convolutional.Conv2D at 0x7fabfb2b7e80>,\n",
       " 'conv2d_138': <keras.layers.convolutional.Conv2D at 0x7fabfb16b6a0>,\n",
       " 'conv2d_143': <keras.layers.convolutional.Conv2D at 0x7fabfaf11898>,\n",
       " 'conv2d_144': <keras.layers.convolutional.Conv2D at 0x7fabfaebfba8>,\n",
       " 'batch_normalization_135': <keras.layers.normalization.BatchNormalization at 0x7fabfb2b7908>,\n",
       " 'batch_normalization_138': <keras.layers.normalization.BatchNormalization at 0x7fabfb127898>,\n",
       " 'batch_normalization_143': <keras.layers.normalization.BatchNormalization at 0x7fabfaed0a90>,\n",
       " 'batch_normalization_144': <keras.layers.normalization.BatchNormalization at 0x7fabfae5b160>,\n",
       " 'activation_135': <keras.layers.core.Activation at 0x7fabfb226b38>,\n",
       " 'activation_138': <keras.layers.core.Activation at 0x7fabfb0f5d30>,\n",
       " 'activation_143': <keras.layers.core.Activation at 0x7fabfaea1f28>,\n",
       " 'activation_144': <keras.layers.core.Activation at 0x7fabfae0fba8>,\n",
       " 'mixed5': <keras.layers.merge.Concatenate at 0x7fabfae729e8>,\n",
       " 'conv2d_149': <keras.layers.convolutional.Conv2D at 0x7fabfacaefd0>,\n",
       " 'batch_normalization_149': <keras.layers.normalization.BatchNormalization at 0x7fabfac08f28>,\n",
       " 'activation_149': <keras.layers.core.Activation at 0x7fabfac3deb8>,\n",
       " 'conv2d_150': <keras.layers.convolutional.Conv2D at 0x7fabfac1fba8>,\n",
       " 'batch_normalization_150': <keras.layers.normalization.BatchNormalization at 0x7fabfabfaf28>,\n",
       " 'activation_150': <keras.layers.core.Activation at 0x7fabfab90a20>,\n",
       " 'conv2d_146': <keras.layers.convolutional.Conv2D at 0x7fabfadcd978>,\n",
       " 'conv2d_151': <keras.layers.convolutional.Conv2D at 0x7fabfab90fd0>,\n",
       " 'batch_normalization_146': <keras.layers.normalization.BatchNormalization at 0x7fabfad9bf98>,\n",
       " 'batch_normalization_151': <keras.layers.normalization.BatchNormalization at 0x7fabfab68f28>,\n",
       " 'activation_146': <keras.layers.core.Activation at 0x7fabfad6ee10>,\n",
       " 'activation_151': <keras.layers.core.Activation at 0x7fabfab01ac8>,\n",
       " 'conv2d_147': <keras.layers.convolutional.Conv2D at 0x7fabfad50e10>,\n",
       " 'conv2d_152': <keras.layers.convolutional.Conv2D at 0x7fabfab01ba8>,\n",
       " 'batch_normalization_147': <keras.layers.normalization.BatchNormalization at 0x7fabfad2ae48>,\n",
       " 'batch_normalization_152': <keras.layers.normalization.BatchNormalization at 0x7fabfab35c50>,\n",
       " 'activation_147': <keras.layers.core.Activation at 0x7fabfad3eac8>,\n",
       " 'activation_152': <keras.layers.core.Activation at 0x7fabfaaedb70>,\n",
       " 'average_pooling2d_15': <keras.layers.pooling.AveragePooling2D at 0x7fabfaa5fcf8>,\n",
       " 'conv2d_145': <keras.layers.convolutional.Conv2D at 0x7fabfae2dd30>,\n",
       " 'conv2d_148': <keras.layers.convolutional.Conv2D at 0x7fabfad3e978>,\n",
       " 'conv2d_153': <keras.layers.convolutional.Conv2D at 0x7fabfaaedc50>,\n",
       " 'conv2d_154': <keras.layers.convolutional.Conv2D at 0x7fabfaa363c8>,\n",
       " 'batch_normalization_145': <keras.layers.normalization.BatchNormalization at 0x7fabfad80e80>,\n",
       " 'batch_normalization_148': <keras.layers.normalization.BatchNormalization at 0x7fabfac99f28>,\n",
       " 'batch_normalization_153': <keras.layers.normalization.BatchNormalization at 0x7fabfaa48940>,\n",
       " 'batch_normalization_154': <keras.layers.normalization.BatchNormalization at 0x7fabfa9cccf8>,\n",
       " 'activation_145': <keras.layers.core.Activation at 0x7fabfade1c18>,\n",
       " 'activation_148': <keras.layers.core.Activation at 0x7fabfacaea20>,\n",
       " 'activation_153': <keras.layers.core.Activation at 0x7fabfaa5fc18>,\n",
       " 'activation_154': <keras.layers.core.Activation at 0x7fabfa9e7470>,\n",
       " 'mixed6': <keras.layers.merge.Concatenate at 0x7fabfa9e72b0>,\n",
       " 'conv2d_159': <keras.layers.convolutional.Conv2D at 0x7fabfa825898>,\n",
       " 'batch_normalization_159': <keras.layers.normalization.BatchNormalization at 0x7fabfa7e2a90>,\n",
       " 'activation_159': <keras.layers.core.Activation at 0x7fabfa74a860>,\n",
       " 'conv2d_160': <keras.layers.convolutional.Conv2D at 0x7fabfa793048>,\n",
       " 'batch_normalization_160': <keras.layers.normalization.BatchNormalization at 0x7fabfa793908>,\n",
       " 'activation_160': <keras.layers.core.Activation at 0x7fabfa721e80>,\n",
       " 'conv2d_156': <keras.layers.convolutional.Conv2D at 0x7fabfa959080>,\n",
       " 'conv2d_161': <keras.layers.convolutional.Conv2D at 0x7fabfa702898>,\n",
       " 'batch_normalization_156': <keras.layers.normalization.BatchNormalization at 0x7fabfa9159e8>,\n",
       " 'batch_normalization_161': <keras.layers.normalization.BatchNormalization at 0x7fabfa6c0a90>,\n",
       " 'activation_156': <keras.layers.core.Activation at 0x7fabfa8847f0>,\n",
       " 'activation_161': <keras.layers.core.Activation at 0x7fabfa692ef0>,\n",
       " 'conv2d_157': <keras.layers.convolutional.Conv2D at 0x7fabfa8c53c8>,\n",
       " 'conv2d_162': <keras.layers.convolutional.Conv2D at 0x7fabfa6f2940>,\n",
       " 'batch_normalization_157': <keras.layers.normalization.BatchNormalization at 0x7fabfa8c5898>,\n",
       " 'batch_normalization_162': <keras.layers.normalization.BatchNormalization at 0x7fabfa648b00>,\n",
       " 'activation_157': <keras.layers.core.Activation at 0x7fabfa856dd8>,\n",
       " 'activation_162': <keras.layers.core.Activation at 0x7fabfa601fd0>,\n",
       " 'average_pooling2d_16': <keras.layers.pooling.AveragePooling2D at 0x7fabfa5ceda0>,\n",
       " 'conv2d_155': <keras.layers.convolutional.Conv2D at 0x7fabfa983f28>,\n",
       " 'conv2d_158': <keras.layers.convolutional.Conv2D at 0x7fabfa8b47f0>,\n",
       " 'conv2d_163': <keras.layers.convolutional.Conv2D at 0x7fabfa660cf8>,\n",
       " 'conv2d_164': <keras.layers.convolutional.Conv2D at 0x7fabfa589c88>,\n",
       " 'batch_normalization_155': <keras.layers.normalization.BatchNormalization at 0x7fabfa9bd240>,\n",
       " 'batch_normalization_158': <keras.layers.normalization.BatchNormalization at 0x7fabfa8739e8>,\n",
       " 'batch_normalization_163': <keras.layers.normalization.BatchNormalization at 0x7fabfa639ba8>,\n",
       " 'batch_normalization_164': <keras.layers.normalization.BatchNormalization at 0x7fabfa5a82b0>,\n",
       " 'activation_155': <keras.layers.core.Activation at 0x7fabfa976ac8>,\n",
       " 'activation_158': <keras.layers.core.Activation at 0x7fabfa7c0e80>,\n",
       " 'activation_163': <keras.layers.core.Activation at 0x7fabfa5ce5c0>,\n",
       " 'activation_164': <keras.layers.core.Activation at 0x7fabfa55bb70>,\n",
       " 'mixed7': <keras.layers.merge.Concatenate at 0x7fabfa5bdb38>,\n",
       " 'conv2d_167': <keras.layers.convolutional.Conv2D at 0x7fabfa49ec18>,\n",
       " 'batch_normalization_167': <keras.layers.normalization.BatchNormalization at 0x7fabfa476908>,\n",
       " 'activation_167': <keras.layers.core.Activation at 0x7fabfa427f98>,\n",
       " 'conv2d_168': <keras.layers.convolutional.Conv2D at 0x7fabfa40cc88>,\n",
       " 'batch_normalization_168': <keras.layers.normalization.BatchNormalization at 0x7fabfa3c5400>,\n",
       " 'activation_168': <keras.layers.core.Activation at 0x7fabfa3fdb38>,\n",
       " 'conv2d_165': <keras.layers.convolutional.Conv2D at 0x7fabfa57a898>,\n",
       " 'conv2d_169': <keras.layers.convolutional.Conv2D at 0x7fabfa3fdc18>,\n",
       " 'batch_normalization_165': <keras.layers.normalization.BatchNormalization at 0x7fabfa518550>,\n",
       " 'batch_normalization_169': <keras.layers.normalization.BatchNormalization at 0x7fabfa358908>,\n",
       " 'activation_165': <keras.layers.core.Activation at 0x7fabfa52ad68>,\n",
       " 'activation_169': <keras.layers.core.Activation at 0x7fabfa36ebe0>,\n",
       " 'conv2d_166': <keras.layers.convolutional.Conv2D at 0x7fabfa52a390>,\n",
       " 'conv2d_170': <keras.layers.convolutional.Conv2D at 0x7fabfa36ecc0>,\n",
       " 'batch_normalization_166': <keras.layers.normalization.BatchNormalization at 0x7fabfa4e5a90>,\n",
       " 'batch_normalization_170': <keras.layers.normalization.BatchNormalization at 0x7fabfa2c49b0>,\n",
       " 'activation_166': <keras.layers.core.Activation at 0x7fabfa49eb38>,\n",
       " 'activation_170': <keras.layers.core.Activation at 0x7fabfa2dbcc0>,\n",
       " 'max_pooling2d_8': <keras.layers.pooling.MaxPooling2D at 0x7fabfa322d68>,\n",
       " 'mixed8': <keras.layers.merge.Concatenate at 0x7fabfa2b0470>,\n",
       " 'conv2d_175': <keras.layers.convolutional.Conv2D at 0x7fabfa1337f0>,\n",
       " 'batch_normalization_175': <keras.layers.normalization.BatchNormalization at 0x7fabfa086048>,\n",
       " 'activation_175': <keras.layers.core.Activation at 0x7fabfa0a37b8>,\n",
       " 'conv2d_172': <keras.layers.convolutional.Conv2D at 0x7fabfa203f98>,\n",
       " 'conv2d_176': <keras.layers.convolutional.Conv2D at 0x7fabfa0a3908>,\n",
       " 'batch_normalization_172': <keras.layers.normalization.BatchNormalization at 0x7fabfa220940>,\n",
       " 'batch_normalization_176': <keras.layers.normalization.BatchNormalization at 0x7fabfa040eb8>,\n",
       " 'activation_172': <keras.layers.core.Activation at 0x7fabfa191748>,\n",
       " 'activation_176': <keras.layers.core.Activation at 0x7fabfa032eb8>,\n",
       " 'conv2d_173': <keras.layers.convolutional.Conv2D at 0x7fabfa1d0320>,\n",
       " 'conv2d_174': <keras.layers.convolutional.Conv2D at 0x7fabfa143748>,\n",
       " 'conv2d_177': <keras.layers.convolutional.Conv2D at 0x7fabfa105e10>,\n",
       " 'conv2d_178': <keras.layers.convolutional.Conv2D at 0x7fabf9f82cc0>,\n",
       " 'average_pooling2d_17': <keras.layers.pooling.AveragePooling2D at 0x7fabf9f29b00>,\n",
       " 'conv2d_171': <keras.layers.convolutional.Conv2D at 0x7fabfa292e10>,\n",
       " 'batch_normalization_173': <keras.layers.normalization.BatchNormalization at 0x7fabfa1d07f0>,\n",
       " 'batch_normalization_174': <keras.layers.normalization.BatchNormalization at 0x7fabfa105908>,\n",
       " 'batch_normalization_177': <keras.layers.normalization.BatchNormalization at 0x7fabf9feaac8>,\n",
       " 'batch_normalization_178': <keras.layers.normalization.BatchNormalization at 0x7fabf9f5ab70>,\n",
       " 'conv2d_179': <keras.layers.convolutional.Conv2D at 0x7fabf9f29978>,\n",
       " 'batch_normalization_171': <keras.layers.normalization.BatchNormalization at 0x7fabfa249d30>,\n",
       " 'activation_173': <keras.layers.core.Activation at 0x7fabfa163cf8>,\n",
       " 'activation_174': <keras.layers.core.Activation at 0x7fabfa0f2748>,\n",
       " 'activation_177': <keras.layers.core.Activation at 0x7fabf9fa1f98>,\n",
       " 'activation_178': <keras.layers.core.Activation at 0x7fabf9f11cc0>,\n",
       " 'batch_normalization_179': <keras.layers.normalization.BatchNormalization at 0x7fabf9ee2eb8>,\n",
       " 'activation_171': <keras.layers.core.Activation at 0x7fabfa203588>,\n",
       " 'mixed9_0': <keras.layers.merge.Concatenate at 0x7fabfa133320>,\n",
       " 'concatenate_3': <keras.layers.merge.Concatenate at 0x7fabf9f6fd68>,\n",
       " 'activation_179': <keras.layers.core.Activation at 0x7fabf9e81be0>,\n",
       " 'mixed9': <keras.layers.merge.Concatenate at 0x7fabf9e819b0>,\n",
       " 'conv2d_184': <keras.layers.convolutional.Conv2D at 0x7fabf9cd9828>,\n",
       " 'batch_normalization_184': <keras.layers.normalization.BatchNormalization at 0x7fabf9cd94a8>,\n",
       " 'activation_184': <keras.layers.core.Activation at 0x7fabf9cadf98>,\n",
       " 'conv2d_181': <keras.layers.convolutional.Conv2D at 0x7fabf9e07898>,\n",
       " 'conv2d_185': <keras.layers.convolutional.Conv2D at 0x7fabf9c93c88>,\n",
       " 'batch_normalization_181': <keras.layers.normalization.BatchNormalization at 0x7fabf9e2e358>,\n",
       " 'batch_normalization_185': <keras.layers.normalization.BatchNormalization at 0x7fabf9c6dac8>,\n",
       " 'activation_181': <keras.layers.core.Activation at 0x7fabf9ddf400>,\n",
       " 'activation_185': <keras.layers.core.Activation at 0x7fabf9c03da0>,\n",
       " 'conv2d_182': <keras.layers.convolutional.Conv2D at 0x7fabf9dc0c88>,\n",
       " 'conv2d_183': <keras.layers.convolutional.Conv2D at 0x7fabf9db2c88>,\n",
       " 'conv2d_186': <keras.layers.convolutional.Conv2D at 0x7fabf9c48ba8>,\n",
       " 'conv2d_187': <keras.layers.convolutional.Conv2D at 0x7fabf9babf98>,\n",
       " 'average_pooling2d_18': <keras.layers.pooling.AveragePooling2D at 0x7fabf9b195f8>,\n",
       " 'conv2d_180': <keras.layers.convolutional.Conv2D at 0x7fabf9e9cf60>,\n",
       " 'batch_normalization_182': <keras.layers.normalization.BatchNormalization at 0x7fabf9df98d0>,\n",
       " 'batch_normalization_183': <keras.layers.normalization.BatchNormalization at 0x7fabf9d0b978>,\n",
       " 'batch_normalization_186': <keras.layers.normalization.BatchNormalization at 0x7fabf9bdeb00>,\n",
       " 'batch_normalization_187': <keras.layers.normalization.BatchNormalization at 0x7fabf9b4a048>,\n",
       " 'conv2d_188': <keras.layers.convolutional.Conv2D at 0x7fabf9b3cac8>,\n",
       " 'batch_normalization_180': <keras.layers.normalization.BatchNormalization at 0x7fabf9e6f978>,\n",
       " 'activation_182': <keras.layers.core.Activation at 0x7fabf9db2ba8>,\n",
       " 'activation_183': <keras.layers.core.Activation at 0x7fabf9d3dd30>,\n",
       " 'activation_186': <keras.layers.core.Activation at 0x7fabf9c3cef0>,\n",
       " 'activation_187': <keras.layers.core.Activation at 0x7fabf9b5e4a8>,\n",
       " 'batch_normalization_188': <keras.layers.normalization.BatchNormalization at 0x7fabf9aea5c0>,\n",
       " 'activation_180': <keras.layers.core.Activation at 0x7fabf9e523c8>,\n",
       " 'mixed9_1': <keras.layers.merge.Concatenate at 0x7fabf9d21c50>,\n",
       " 'concatenate_4': <keras.layers.merge.Concatenate at 0x7fabf9b5eef0>,\n",
       " 'activation_188': <keras.layers.core.Activation at 0x7fabf9a8ae10>,\n",
       " 'mixed10': <keras.layers.merge.Concatenate at 0x7fabf9a8a9e8>}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as in making visible the layers activation in chapter 5, we define a gradient ascent process.\n",
    "\n",
    "# This holds our generated image\n",
    "dream = model.input\n",
    "\n",
    "# Compute the gradients of the dream with regard to the loss.\n",
    "grads = K.gradients(loss, dream)[0]\n",
    "\n",
    "# Normalize gradients --> important trick\n",
    "grads /= K.maximum(K.mean(K.abs(grads)), 1e-7)\n",
    "\n",
    "# Set up function to retrieve the value\n",
    "# of the loss and gradients given an input image.\n",
    "outputs = [loss, grads]\n",
    "fetch_loss_and_grads = K.function([dream], outputs)\n",
    "\n",
    "def eval_loss_and_grads(x):\n",
    "    outs = fetch_loss_and_grads([x])\n",
    "    loss_value = outs[0]\n",
    "    grad_values = outs[1]\n",
    "    return loss_value, grad_values\n",
    "\n",
    "def gradient_ascent(x, iterations, step, max_loss=None):\n",
    "    for i in range(iterations):\n",
    "        loss_value, grad_values = eval_loss_and_grads(x)\n",
    "        if max_loss is not None and loss_value > max_loss:\n",
    "            break\n",
    "        print('...Loss value at', i, ':', loss_value)\n",
    "        x += step * grad_values\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining auxiliary numpy functions for the deepdream algorithm\n",
    "\n",
    "import scipy\n",
    "from keras.preprocessing import image\n",
    "\n",
    "def resize_img(img, size):\n",
    "    img = np.copy(img)\n",
    "    factors = (1,\n",
    "               float(size[0]) / img.shape[1],\n",
    "               float(size[1]) / img.shape[2],\n",
    "               1)\n",
    "    return scipy.ndimage.zoom(img, factors, order=1)\n",
    "\n",
    "\n",
    "def save_img(img, fname):\n",
    "    pil_img = deprocess_image(np.copy(img))\n",
    "    scipy.misc.imsave(fname, pil_img)\n",
    "\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    # Util function to open, resize and format pictures\n",
    "    # into appropriate tensors.\n",
    "    img = image.load_img(image_path)\n",
    "    img = image.img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = inception_v3.preprocess_input(img)\n",
    "    return img\n",
    "\n",
    "\n",
    "def deprocess_image(x):\n",
    "    # Util function to convert a tensor into a valid image.\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        x = x.reshape((3, x.shape[2], x.shape[3]))\n",
    "        x = x.transpose((1, 2, 0))\n",
    "    else:\n",
    "        x = x.reshape((x.shape[1], x.shape[2], 3))\n",
    "    x /= 2.\n",
    "    x += 0.5\n",
    "    x *= 255.\n",
    "    x = np.clip(x, 0, 255).astype('uint8')\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joel/anaconda3/lib/python3.7/site-packages/scipy/ndimage/interpolation.py:605: UserWarning: From scipy 0.13.0, the output shape of zoom() is calculated with round() instead of int() - for these inputs the size of the returned array has changed.\n",
      "  \"the returned array has changed.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image shape (1175, 1763)\n",
      "...Loss value at 0 : 1.2755861\n",
      "...Loss value at 1 : 1.9073415\n",
      "...Loss value at 2 : 2.7064319\n",
      "...Loss value at 3 : 3.645239\n",
      "...Loss value at 4 : 4.581405\n",
      "...Loss value at 5 : 5.4915633\n",
      "...Loss value at 6 : 6.370616\n",
      "...Loss value at 7 : 7.231332\n",
      "...Loss value at 8 : 8.059938\n",
      "...Loss value at 9 : 8.857846\n",
      "...Loss value at 10 : 9.642599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joel/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:17: DeprecationWarning: `imsave` is deprecated!\n",
      "`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imwrite`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image shape (1645, 2468)\n",
      "...Loss value at 0 : 3.703653\n",
      "...Loss value at 1 : 5.2247214\n",
      "...Loss value at 2 : 6.412139\n",
      "...Loss value at 3 : 7.46295\n",
      "...Loss value at 4 : 8.454355\n",
      "...Loss value at 5 : 9.386311\n",
      "Processing image shape (2304, 3456)\n",
      "...Loss value at 0 : 3.5648026\n",
      "...Loss value at 1 : 4.989954\n",
      "...Loss value at 2 : 6.160798\n",
      "...Loss value at 3 : 7.2511234\n",
      "...Loss value at 4 : 8.305636\n",
      "...Loss value at 5 : 9.311065\n"
     ]
    }
   ],
   "source": [
    "# We start by defining a list of scales at which to process the image.\n",
    "# Then we process a small image with the deepdream algorithm, scale it up by 40% and go on like this.\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Playing with these hyperparameters will also allow you to achieve new effects\n",
    "\n",
    "step = 0.01  # Gradient ascent step size\n",
    "num_octave = 3  # Number of scales at which to run gradient ascent\n",
    "octave_scale = 1.4  # Size ratio between scales\n",
    "iterations = 20  # Number of ascent steps per scale\n",
    "\n",
    "# If our loss gets larger than 10,\n",
    "# we will interrupt the gradient ascent process, to avoid ugly artifacts\n",
    "max_loss = 10.\n",
    "\n",
    "# Fill this to the path to the image you want to use\n",
    "base_image_path = '/home/joel/DL_Python/generative_dl/IMG_3405.JPG'\n",
    "\n",
    "# Load the image into a Numpy array\n",
    "img = preprocess_image(base_image_path)\n",
    "\n",
    "# We prepare a list of shape tuples\n",
    "# defining the different scales at which we will run gradient ascent\n",
    "original_shape = img.shape[1:3]\n",
    "successive_shapes = [original_shape]\n",
    "for i in range(1, num_octave):\n",
    "    shape = tuple([int(dim / (octave_scale ** i)) for dim in original_shape])\n",
    "    successive_shapes.append(shape)\n",
    "\n",
    "# Reverse list of shapes, so that they are in increasing order\n",
    "successive_shapes = successive_shapes[::-1]\n",
    "\n",
    "# Resize the Numpy array of the image to our smallest scale\n",
    "original_img = np.copy(img)\n",
    "shrunk_original_img = resize_img(img, successive_shapes[0])\n",
    "\n",
    "for shape in successive_shapes:\n",
    "    print('Processing image shape', shape)\n",
    "    img = resize_img(img, shape)\n",
    "    img = gradient_ascent(img,\n",
    "                          iterations=iterations,\n",
    "                          step=step,\n",
    "                          max_loss=max_loss)\n",
    "    upscaled_shrunk_original_img = resize_img(shrunk_original_img, shape)\n",
    "    same_size_original = resize_img(original_img, shape)\n",
    "    lost_detail = same_size_original - upscaled_shrunk_original_img\n",
    "\n",
    "    img += lost_detail\n",
    "    shrunk_original_img = resize_img(original_img, shape)\n",
    "    save_img(img, fname='dream_at_scale_' + str(shape) + '.png')\n",
    "\n",
    "save_img(img, fname='final_dream.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
