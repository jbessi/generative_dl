{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading pretrained inception V3 model for generating deep dream images\n",
    "\n",
    "import keras\n",
    "from keras.applications import inception_v3\n",
    "from keras import backend as K\n",
    "\n",
    "# We will not be training our model,\n",
    "# so we use this command to disable all training-specific operations\n",
    "K.set_learning_phase(0)\n",
    "\n",
    "# Build the InceptionV3 network.\n",
    "# The model will be loaded with pre-trained ImageNet weights.\n",
    "model = inception_v3.InceptionV3(weights='imagenet',\n",
    "                                 include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting the deepdream config, i.e. what layers should contribute to the final image\n",
    "# this is a somewhat arbitraty selection but can be changed and experimented with\n",
    "\n",
    "# Dict mapping layer names to a coefficient quantifying how much the layer's activation\n",
    "# will contribute to the loss we will seek to maximize.\n",
    "# Note that these are layer names as they appear in the built-in InceptionV3 application.\n",
    "# You can list all layer names using `model.summary()`.\n",
    "layer_contributions = {\n",
    "    'mixed8': 0.2,\n",
    "    'mixed3': 3.,\n",
    "    'mixed5': 2.,\n",
    "    'conv2d_180': 1.5,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_2 (InputLayer)             (None, None, None, 3) 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)               (None, None, None, 32 864         input_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNor (None, None, None, 32 96          conv2d_95[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_95 (Activation)       (None, None, None, 32 0           batch_normalization_95[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)               (None, None, None, 32 9216        activation_95[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNor (None, None, None, 32 96          conv2d_96[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_96 (Activation)       (None, None, None, 32 0           batch_normalization_96[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)               (None, None, None, 64 18432       activation_96[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNor (None, None, None, 64 192         conv2d_97[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_97 (Activation)       (None, None, None, 64 0           batch_normalization_97[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)   (None, None, None, 64 0           activation_97[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)               (None, None, None, 80 5120        max_pooling2d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNor (None, None, None, 80 240         conv2d_98[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_98 (Activation)       (None, None, None, 80 0           batch_normalization_98[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)               (None, None, None, 19 138240      activation_98[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_99 (BatchNor (None, None, None, 19 576         conv2d_99[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_99 (Activation)       (None, None, None, 19 0           batch_normalization_99[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)   (None, None, None, 19 0           activation_99[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)              (None, None, None, 64 12288       max_pooling2d_6[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_103 (BatchNo (None, None, None, 64 192         conv2d_103[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_103 (Activation)      (None, None, None, 64 0           batch_normalization_103[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)              (None, None, None, 48 9216        max_pooling2d_6[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)              (None, None, None, 96 55296       activation_103[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_101 (BatchNo (None, None, None, 48 144         conv2d_101[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_104 (BatchNo (None, None, None, 96 288         conv2d_104[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_101 (Activation)      (None, None, None, 48 0           batch_normalization_101[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_104 (Activation)      (None, None, None, 96 0           batch_normalization_104[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_10 (AveragePoo (None, None, None, 19 0           max_pooling2d_6[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)              (None, None, None, 64 12288       max_pooling2d_6[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)              (None, None, None, 64 76800       activation_101[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)              (None, None, None, 96 82944       activation_104[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_106 (Conv2D)              (None, None, None, 32 6144        average_pooling2d_10[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_100 (BatchNo (None, None, None, 64 192         conv2d_100[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_102 (BatchNo (None, None, None, 64 192         conv2d_102[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_105 (BatchNo (None, None, None, 96 288         conv2d_105[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_106 (BatchNo (None, None, None, 32 96          conv2d_106[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_100 (Activation)      (None, None, None, 64 0           batch_normalization_100[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_102 (Activation)      (None, None, None, 64 0           batch_normalization_102[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_105 (Activation)      (None, None, None, 96 0           batch_normalization_105[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_106 (Activation)      (None, None, None, 32 0           batch_normalization_106[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)             (None, None, None, 25 0           activation_100[0][0]             \n",
      "                                                                   activation_102[0][0]             \n",
      "                                                                   activation_105[0][0]             \n",
      "                                                                   activation_106[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_110 (Conv2D)              (None, None, None, 64 16384       mixed0[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_110 (BatchNo (None, None, None, 64 192         conv2d_110[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_110 (Activation)      (None, None, None, 64 0           batch_normalization_110[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_108 (Conv2D)              (None, None, None, 48 12288       mixed0[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_111 (Conv2D)              (None, None, None, 96 55296       activation_110[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_108 (BatchNo (None, None, None, 48 144         conv2d_108[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_111 (BatchNo (None, None, None, 96 288         conv2d_111[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_108 (Activation)      (None, None, None, 48 0           batch_normalization_108[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_111 (Activation)      (None, None, None, 96 0           batch_normalization_111[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_11 (AveragePoo (None, None, None, 25 0           mixed0[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_107 (Conv2D)              (None, None, None, 64 16384       mixed0[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_109 (Conv2D)              (None, None, None, 64 76800       activation_108[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_112 (Conv2D)              (None, None, None, 96 82944       activation_111[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_113 (Conv2D)              (None, None, None, 64 16384       average_pooling2d_11[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_107 (BatchNo (None, None, None, 64 192         conv2d_107[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_109 (BatchNo (None, None, None, 64 192         conv2d_109[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_112 (BatchNo (None, None, None, 96 288         conv2d_112[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_113 (BatchNo (None, None, None, 64 192         conv2d_113[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_107 (Activation)      (None, None, None, 64 0           batch_normalization_107[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_109 (Activation)      (None, None, None, 64 0           batch_normalization_109[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_112 (Activation)      (None, None, None, 96 0           batch_normalization_112[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_113 (Activation)      (None, None, None, 64 0           batch_normalization_113[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)             (None, None, None, 28 0           activation_107[0][0]             \n",
      "                                                                   activation_109[0][0]             \n",
      "                                                                   activation_112[0][0]             \n",
      "                                                                   activation_113[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_117 (Conv2D)              (None, None, None, 64 18432       mixed1[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_117 (BatchNo (None, None, None, 64 192         conv2d_117[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_117 (Activation)      (None, None, None, 64 0           batch_normalization_117[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_115 (Conv2D)              (None, None, None, 48 13824       mixed1[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_118 (Conv2D)              (None, None, None, 96 55296       activation_117[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_115 (BatchNo (None, None, None, 48 144         conv2d_115[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_118 (BatchNo (None, None, None, 96 288         conv2d_118[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_115 (Activation)      (None, None, None, 48 0           batch_normalization_115[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_118 (Activation)      (None, None, None, 96 0           batch_normalization_118[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_12 (AveragePoo (None, None, None, 28 0           mixed1[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_114 (Conv2D)              (None, None, None, 64 18432       mixed1[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_116 (Conv2D)              (None, None, None, 64 76800       activation_115[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_119 (Conv2D)              (None, None, None, 96 82944       activation_118[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_120 (Conv2D)              (None, None, None, 64 18432       average_pooling2d_12[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_114 (BatchNo (None, None, None, 64 192         conv2d_114[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_116 (BatchNo (None, None, None, 64 192         conv2d_116[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_119 (BatchNo (None, None, None, 96 288         conv2d_119[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_120 (BatchNo (None, None, None, 64 192         conv2d_120[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_114 (Activation)      (None, None, None, 64 0           batch_normalization_114[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_116 (Activation)      (None, None, None, 64 0           batch_normalization_116[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_119 (Activation)      (None, None, None, 96 0           batch_normalization_119[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_120 (Activation)      (None, None, None, 64 0           batch_normalization_120[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)             (None, None, None, 28 0           activation_114[0][0]             \n",
      "                                                                   activation_116[0][0]             \n",
      "                                                                   activation_119[0][0]             \n",
      "                                                                   activation_120[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_122 (Conv2D)              (None, None, None, 64 18432       mixed2[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_122 (BatchNo (None, None, None, 64 192         conv2d_122[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_122 (Activation)      (None, None, None, 64 0           batch_normalization_122[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_123 (Conv2D)              (None, None, None, 96 55296       activation_122[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_123 (BatchNo (None, None, None, 96 288         conv2d_123[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_123 (Activation)      (None, None, None, 96 0           batch_normalization_123[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_121 (Conv2D)              (None, None, None, 38 995328      mixed2[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_124 (Conv2D)              (None, None, None, 96 82944       activation_123[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_121 (BatchNo (None, None, None, 38 1152        conv2d_121[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_124 (BatchNo (None, None, None, 96 288         conv2d_124[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_121 (Activation)      (None, None, None, 38 0           batch_normalization_121[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_124 (Activation)      (None, None, None, 96 0           batch_normalization_124[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)   (None, None, None, 28 0           mixed2[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)             (None, None, None, 76 0           activation_121[0][0]             \n",
      "                                                                   activation_124[0][0]             \n",
      "                                                                   max_pooling2d_7[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_129 (Conv2D)              (None, None, None, 12 98304       mixed3[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_129 (BatchNo (None, None, None, 12 384         conv2d_129[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_129 (Activation)      (None, None, None, 12 0           batch_normalization_129[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_130 (Conv2D)              (None, None, None, 12 114688      activation_129[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_130 (BatchNo (None, None, None, 12 384         conv2d_130[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_130 (Activation)      (None, None, None, 12 0           batch_normalization_130[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_126 (Conv2D)              (None, None, None, 12 98304       mixed3[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_131 (Conv2D)              (None, None, None, 12 114688      activation_130[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_126 (BatchNo (None, None, None, 12 384         conv2d_126[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_131 (BatchNo (None, None, None, 12 384         conv2d_131[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_126 (Activation)      (None, None, None, 12 0           batch_normalization_126[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_131 (Activation)      (None, None, None, 12 0           batch_normalization_131[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_127 (Conv2D)              (None, None, None, 12 114688      activation_126[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_132 (Conv2D)              (None, None, None, 12 114688      activation_131[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_127 (BatchNo (None, None, None, 12 384         conv2d_127[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_132 (BatchNo (None, None, None, 12 384         conv2d_132[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_127 (Activation)      (None, None, None, 12 0           batch_normalization_127[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_132 (Activation)      (None, None, None, 12 0           batch_normalization_132[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_13 (AveragePoo (None, None, None, 76 0           mixed3[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_125 (Conv2D)              (None, None, None, 19 147456      mixed3[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_128 (Conv2D)              (None, None, None, 19 172032      activation_127[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_133 (Conv2D)              (None, None, None, 19 172032      activation_132[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_134 (Conv2D)              (None, None, None, 19 147456      average_pooling2d_13[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_125 (BatchNo (None, None, None, 19 576         conv2d_125[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_128 (BatchNo (None, None, None, 19 576         conv2d_128[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_133 (BatchNo (None, None, None, 19 576         conv2d_133[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_134 (BatchNo (None, None, None, 19 576         conv2d_134[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_125 (Activation)      (None, None, None, 19 0           batch_normalization_125[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_128 (Activation)      (None, None, None, 19 0           batch_normalization_128[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_133 (Activation)      (None, None, None, 19 0           batch_normalization_133[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_134 (Activation)      (None, None, None, 19 0           batch_normalization_134[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)             (None, None, None, 76 0           activation_125[0][0]             \n",
      "                                                                   activation_128[0][0]             \n",
      "                                                                   activation_133[0][0]             \n",
      "                                                                   activation_134[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_139 (Conv2D)              (None, None, None, 16 122880      mixed4[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_139 (BatchNo (None, None, None, 16 480         conv2d_139[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_139 (Activation)      (None, None, None, 16 0           batch_normalization_139[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_140 (Conv2D)              (None, None, None, 16 179200      activation_139[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_140 (BatchNo (None, None, None, 16 480         conv2d_140[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_140 (Activation)      (None, None, None, 16 0           batch_normalization_140[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_136 (Conv2D)              (None, None, None, 16 122880      mixed4[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_141 (Conv2D)              (None, None, None, 16 179200      activation_140[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_136 (BatchNo (None, None, None, 16 480         conv2d_136[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_141 (BatchNo (None, None, None, 16 480         conv2d_141[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_136 (Activation)      (None, None, None, 16 0           batch_normalization_136[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_141 (Activation)      (None, None, None, 16 0           batch_normalization_141[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_137 (Conv2D)              (None, None, None, 16 179200      activation_136[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_142 (Conv2D)              (None, None, None, 16 179200      activation_141[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_137 (BatchNo (None, None, None, 16 480         conv2d_137[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_142 (BatchNo (None, None, None, 16 480         conv2d_142[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_137 (Activation)      (None, None, None, 16 0           batch_normalization_137[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_142 (Activation)      (None, None, None, 16 0           batch_normalization_142[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_14 (AveragePoo (None, None, None, 76 0           mixed4[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_135 (Conv2D)              (None, None, None, 19 147456      mixed4[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_138 (Conv2D)              (None, None, None, 19 215040      activation_137[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_143 (Conv2D)              (None, None, None, 19 215040      activation_142[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_144 (Conv2D)              (None, None, None, 19 147456      average_pooling2d_14[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_135 (BatchNo (None, None, None, 19 576         conv2d_135[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_138 (BatchNo (None, None, None, 19 576         conv2d_138[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_143 (BatchNo (None, None, None, 19 576         conv2d_143[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_144 (BatchNo (None, None, None, 19 576         conv2d_144[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_135 (Activation)      (None, None, None, 19 0           batch_normalization_135[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_138 (Activation)      (None, None, None, 19 0           batch_normalization_138[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_143 (Activation)      (None, None, None, 19 0           batch_normalization_143[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_144 (Activation)      (None, None, None, 19 0           batch_normalization_144[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)             (None, None, None, 76 0           activation_135[0][0]             \n",
      "                                                                   activation_138[0][0]             \n",
      "                                                                   activation_143[0][0]             \n",
      "                                                                   activation_144[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_149 (Conv2D)              (None, None, None, 16 122880      mixed5[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_149 (BatchNo (None, None, None, 16 480         conv2d_149[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_149 (Activation)      (None, None, None, 16 0           batch_normalization_149[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_150 (Conv2D)              (None, None, None, 16 179200      activation_149[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_150 (BatchNo (None, None, None, 16 480         conv2d_150[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_150 (Activation)      (None, None, None, 16 0           batch_normalization_150[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_146 (Conv2D)              (None, None, None, 16 122880      mixed5[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_151 (Conv2D)              (None, None, None, 16 179200      activation_150[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_146 (BatchNo (None, None, None, 16 480         conv2d_146[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_151 (BatchNo (None, None, None, 16 480         conv2d_151[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_146 (Activation)      (None, None, None, 16 0           batch_normalization_146[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_151 (Activation)      (None, None, None, 16 0           batch_normalization_151[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_147 (Conv2D)              (None, None, None, 16 179200      activation_146[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_152 (Conv2D)              (None, None, None, 16 179200      activation_151[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_147 (BatchNo (None, None, None, 16 480         conv2d_147[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_152 (BatchNo (None, None, None, 16 480         conv2d_152[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_147 (Activation)      (None, None, None, 16 0           batch_normalization_147[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_152 (Activation)      (None, None, None, 16 0           batch_normalization_152[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_15 (AveragePoo (None, None, None, 76 0           mixed5[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_145 (Conv2D)              (None, None, None, 19 147456      mixed5[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_148 (Conv2D)              (None, None, None, 19 215040      activation_147[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_153 (Conv2D)              (None, None, None, 19 215040      activation_152[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_154 (Conv2D)              (None, None, None, 19 147456      average_pooling2d_15[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_145 (BatchNo (None, None, None, 19 576         conv2d_145[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_148 (BatchNo (None, None, None, 19 576         conv2d_148[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_153 (BatchNo (None, None, None, 19 576         conv2d_153[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_154 (BatchNo (None, None, None, 19 576         conv2d_154[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_145 (Activation)      (None, None, None, 19 0           batch_normalization_145[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_148 (Activation)      (None, None, None, 19 0           batch_normalization_148[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_153 (Activation)      (None, None, None, 19 0           batch_normalization_153[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_154 (Activation)      (None, None, None, 19 0           batch_normalization_154[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)             (None, None, None, 76 0           activation_145[0][0]             \n",
      "                                                                   activation_148[0][0]             \n",
      "                                                                   activation_153[0][0]             \n",
      "                                                                   activation_154[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_159 (Conv2D)              (None, None, None, 19 147456      mixed6[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_159 (BatchNo (None, None, None, 19 576         conv2d_159[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_159 (Activation)      (None, None, None, 19 0           batch_normalization_159[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_160 (Conv2D)              (None, None, None, 19 258048      activation_159[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_160 (BatchNo (None, None, None, 19 576         conv2d_160[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_160 (Activation)      (None, None, None, 19 0           batch_normalization_160[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_156 (Conv2D)              (None, None, None, 19 147456      mixed6[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_161 (Conv2D)              (None, None, None, 19 258048      activation_160[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_156 (BatchNo (None, None, None, 19 576         conv2d_156[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_161 (BatchNo (None, None, None, 19 576         conv2d_161[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_156 (Activation)      (None, None, None, 19 0           batch_normalization_156[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_161 (Activation)      (None, None, None, 19 0           batch_normalization_161[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_157 (Conv2D)              (None, None, None, 19 258048      activation_156[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_162 (Conv2D)              (None, None, None, 19 258048      activation_161[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_157 (BatchNo (None, None, None, 19 576         conv2d_157[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_162 (BatchNo (None, None, None, 19 576         conv2d_162[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_157 (Activation)      (None, None, None, 19 0           batch_normalization_157[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_162 (Activation)      (None, None, None, 19 0           batch_normalization_162[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_16 (AveragePoo (None, None, None, 76 0           mixed6[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_155 (Conv2D)              (None, None, None, 19 147456      mixed6[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_158 (Conv2D)              (None, None, None, 19 258048      activation_157[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_163 (Conv2D)              (None, None, None, 19 258048      activation_162[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_164 (Conv2D)              (None, None, None, 19 147456      average_pooling2d_16[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_155 (BatchNo (None, None, None, 19 576         conv2d_155[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_158 (BatchNo (None, None, None, 19 576         conv2d_158[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_163 (BatchNo (None, None, None, 19 576         conv2d_163[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_164 (BatchNo (None, None, None, 19 576         conv2d_164[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_155 (Activation)      (None, None, None, 19 0           batch_normalization_155[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_158 (Activation)      (None, None, None, 19 0           batch_normalization_158[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_163 (Activation)      (None, None, None, 19 0           batch_normalization_163[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_164 (Activation)      (None, None, None, 19 0           batch_normalization_164[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)             (None, None, None, 76 0           activation_155[0][0]             \n",
      "                                                                   activation_158[0][0]             \n",
      "                                                                   activation_163[0][0]             \n",
      "                                                                   activation_164[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_167 (Conv2D)              (None, None, None, 19 147456      mixed7[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_167 (BatchNo (None, None, None, 19 576         conv2d_167[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_167 (Activation)      (None, None, None, 19 0           batch_normalization_167[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_168 (Conv2D)              (None, None, None, 19 258048      activation_167[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_168 (BatchNo (None, None, None, 19 576         conv2d_168[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_168 (Activation)      (None, None, None, 19 0           batch_normalization_168[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_165 (Conv2D)              (None, None, None, 19 147456      mixed7[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_169 (Conv2D)              (None, None, None, 19 258048      activation_168[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_165 (BatchNo (None, None, None, 19 576         conv2d_165[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_169 (BatchNo (None, None, None, 19 576         conv2d_169[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_165 (Activation)      (None, None, None, 19 0           batch_normalization_165[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_169 (Activation)      (None, None, None, 19 0           batch_normalization_169[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_166 (Conv2D)              (None, None, None, 32 552960      activation_165[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_170 (Conv2D)              (None, None, None, 19 331776      activation_169[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_166 (BatchNo (None, None, None, 32 960         conv2d_166[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_170 (BatchNo (None, None, None, 19 576         conv2d_170[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_166 (Activation)      (None, None, None, 32 0           batch_normalization_166[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_170 (Activation)      (None, None, None, 19 0           batch_normalization_170[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)   (None, None, None, 76 0           mixed7[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)             (None, None, None, 12 0           activation_166[0][0]             \n",
      "                                                                   activation_170[0][0]             \n",
      "                                                                   max_pooling2d_8[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_175 (Conv2D)              (None, None, None, 44 573440      mixed8[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_175 (BatchNo (None, None, None, 44 1344        conv2d_175[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_175 (Activation)      (None, None, None, 44 0           batch_normalization_175[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_172 (Conv2D)              (None, None, None, 38 491520      mixed8[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_176 (Conv2D)              (None, None, None, 38 1548288     activation_175[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_172 (BatchNo (None, None, None, 38 1152        conv2d_172[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_176 (BatchNo (None, None, None, 38 1152        conv2d_176[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_172 (Activation)      (None, None, None, 38 0           batch_normalization_172[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_176 (Activation)      (None, None, None, 38 0           batch_normalization_176[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_173 (Conv2D)              (None, None, None, 38 442368      activation_172[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_174 (Conv2D)              (None, None, None, 38 442368      activation_172[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_177 (Conv2D)              (None, None, None, 38 442368      activation_176[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_178 (Conv2D)              (None, None, None, 38 442368      activation_176[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_17 (AveragePoo (None, None, None, 12 0           mixed8[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_171 (Conv2D)              (None, None, None, 32 409600      mixed8[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_173 (BatchNo (None, None, None, 38 1152        conv2d_173[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_174 (BatchNo (None, None, None, 38 1152        conv2d_174[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_177 (BatchNo (None, None, None, 38 1152        conv2d_177[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_178 (BatchNo (None, None, None, 38 1152        conv2d_178[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_179 (Conv2D)              (None, None, None, 19 245760      average_pooling2d_17[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_171 (BatchNo (None, None, None, 32 960         conv2d_171[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_173 (Activation)      (None, None, None, 38 0           batch_normalization_173[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_174 (Activation)      (None, None, None, 38 0           batch_normalization_174[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_177 (Activation)      (None, None, None, 38 0           batch_normalization_177[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_178 (Activation)      (None, None, None, 38 0           batch_normalization_178[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_179 (BatchNo (None, None, None, 19 576         conv2d_179[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_171 (Activation)      (None, None, None, 32 0           batch_normalization_171[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)           (None, None, None, 76 0           activation_173[0][0]             \n",
      "                                                                   activation_174[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)      (None, None, None, 76 0           activation_177[0][0]             \n",
      "                                                                   activation_178[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_179 (Activation)      (None, None, None, 19 0           batch_normalization_179[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)             (None, None, None, 20 0           activation_171[0][0]             \n",
      "                                                                   mixed9_0[0][0]                   \n",
      "                                                                   concatenate_3[0][0]              \n",
      "                                                                   activation_179[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_184 (Conv2D)              (None, None, None, 44 917504      mixed9[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_184 (BatchNo (None, None, None, 44 1344        conv2d_184[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_184 (Activation)      (None, None, None, 44 0           batch_normalization_184[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_181 (Conv2D)              (None, None, None, 38 786432      mixed9[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_185 (Conv2D)              (None, None, None, 38 1548288     activation_184[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_181 (BatchNo (None, None, None, 38 1152        conv2d_181[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_185 (BatchNo (None, None, None, 38 1152        conv2d_185[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_181 (Activation)      (None, None, None, 38 0           batch_normalization_181[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_185 (Activation)      (None, None, None, 38 0           batch_normalization_185[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_182 (Conv2D)              (None, None, None, 38 442368      activation_181[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_183 (Conv2D)              (None, None, None, 38 442368      activation_181[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_186 (Conv2D)              (None, None, None, 38 442368      activation_185[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_187 (Conv2D)              (None, None, None, 38 442368      activation_185[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_18 (AveragePoo (None, None, None, 20 0           mixed9[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_180 (Conv2D)              (None, None, None, 32 655360      mixed9[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_182 (BatchNo (None, None, None, 38 1152        conv2d_182[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_183 (BatchNo (None, None, None, 38 1152        conv2d_183[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_186 (BatchNo (None, None, None, 38 1152        conv2d_186[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_187 (BatchNo (None, None, None, 38 1152        conv2d_187[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_188 (Conv2D)              (None, None, None, 19 393216      average_pooling2d_18[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_180 (BatchNo (None, None, None, 32 960         conv2d_180[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_182 (Activation)      (None, None, None, 38 0           batch_normalization_182[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_183 (Activation)      (None, None, None, 38 0           batch_normalization_183[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_186 (Activation)      (None, None, None, 38 0           batch_normalization_186[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_187 (Activation)      (None, None, None, 38 0           batch_normalization_187[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_188 (BatchNo (None, None, None, 19 576         conv2d_188[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_180 (Activation)      (None, None, None, 32 0           batch_normalization_180[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)           (None, None, None, 76 0           activation_182[0][0]             \n",
      "                                                                   activation_183[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)      (None, None, None, 76 0           activation_186[0][0]             \n",
      "                                                                   activation_187[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_188 (Activation)      (None, None, None, 19 0           batch_normalization_188[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)            (None, None, None, 20 0           activation_180[0][0]             \n",
      "                                                                   mixed9_1[0][0]                   \n",
      "                                                                   concatenate_4[0][0]              \n",
      "                                                                   activation_188[0][0]             \n",
      "====================================================================================================\n",
      "Total params: 21,802,784\n",
      "Trainable params: 21,768,352\n",
      "Non-trainable params: 34,432\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0716 13:57:49.736019 140157247465216 variables.py:2569] Variable += will be deprecated. Use variable.assign_add if you want assignment to the variable value or 'x = x + y' if you want a new python Tensor object.\n"
     ]
    }
   ],
   "source": [
    "# defininig a loss by the weighted sum of L2 norm of the activations of the layers defined above\n",
    "\n",
    "# Get the symbolic outputs of each \"key\" layer (we gave them unique names).\n",
    "layer_dict = dict([(layer.name, layer) for layer in model.layers])\n",
    "\n",
    "# Define the loss.\n",
    "loss = K.variable(0.) #instantiating a variable with value 0\n",
    "for layer_name in layer_contributions:\n",
    "    # Add the L2 norm of the features of a layer to the loss.\n",
    "    coeff = layer_contributions[layer_name]\n",
    "    activation = layer_dict[layer_name].output\n",
    "    # We avoid border artifacts by only involving non-border pixels in the loss.\n",
    "    scaling = K.prod(K.cast(K.shape(activation), 'float32'))\n",
    "    loss += coeff * K.sum(K.square(activation[:, 2: -2, 2: -2, :])) / scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation_100': <keras.layers.core.Activation at 0x7f78bd9088d0>,\n",
       " 'activation_101': <keras.layers.core.Activation at 0x7f78bd8b2860>,\n",
       " 'activation_102': <keras.layers.core.Activation at 0x7f78bd885860>,\n",
       " 'activation_103': <keras.layers.core.Activation at 0x7f78bd867f28>,\n",
       " 'activation_104': <keras.layers.core.Activation at 0x7f78bd7ccac8>,\n",
       " 'activation_105': <keras.layers.core.Activation at 0x7f78bd748860>,\n",
       " 'activation_106': <keras.layers.core.Activation at 0x7f78bd6ffa20>,\n",
       " 'activation_107': <keras.layers.core.Activation at 0x7f78bd6e1908>,\n",
       " 'activation_108': <keras.layers.core.Activation at 0x7f78bd6438d0>,\n",
       " 'activation_109': <keras.layers.core.Activation at 0x7f78bd624e48>,\n",
       " 'activation_110': <keras.layers.core.Activation at 0x7f78bd5890f0>,\n",
       " 'activation_111': <keras.layers.core.Activation at 0x7f78bd559cc0>,\n",
       " 'activation_112': <keras.layers.core.Activation at 0x7f78bd4be9e8>,\n",
       " 'activation_113': <keras.layers.core.Activation at 0x7f78bd49c6a0>,\n",
       " 'activation_114': <keras.layers.core.Activation at 0x7f78bd3b1208>,\n",
       " 'activation_115': <keras.layers.core.Activation at 0x7f78bd3e1eb8>,\n",
       " 'activation_116': <keras.layers.core.Activation at 0x7f78bd346a58>,\n",
       " 'activation_117': <keras.layers.core.Activation at 0x7f78bd2c28d0>,\n",
       " 'activation_118': <keras.layers.core.Activation at 0x7f78bd2798d0>,\n",
       " 'activation_119': <keras.layers.core.Activation at 0x7f787b0c7f98>,\n",
       " 'activation_120': <keras.layers.core.Activation at 0x7f787b040e48>,\n",
       " 'activation_121': <keras.layers.core.Activation at 0x7f78706584e0>,\n",
       " 'activation_122': <keras.layers.core.Activation at 0x7f787061f080>,\n",
       " 'activation_123': <keras.layers.core.Activation at 0x7f78705f0c50>,\n",
       " 'activation_124': <keras.layers.core.Activation at 0x7f7870556940>,\n",
       " 'activation_125': <keras.layers.core.Activation at 0x7f7870534630>,\n",
       " 'activation_126': <keras.layers.core.Activation at 0x7f7870498748>,\n",
       " 'activation_127': <keras.layers.core.Activation at 0x7f7870412748>,\n",
       " 'activation_128': <keras.layers.core.Activation at 0x7f78703de9b0>,\n",
       " 'activation_129': <keras.layers.core.Activation at 0x7f78703bf828>,\n",
       " 'activation_130': <keras.layers.core.Activation at 0x7f7870311828>,\n",
       " 'activation_131': <keras.layers.core.Activation at 0x7f78702f2ef0>,\n",
       " 'activation_132': <keras.layers.core.Activation at 0x7f7870257be0>,\n",
       " 'activation_133': <keras.layers.core.Activation at 0x7f78701d2390>,\n",
       " 'activation_134': <keras.layers.core.Activation at 0x7f78701b7780>,\n",
       " 'activation_135': <keras.layers.core.Activation at 0x7f787016ba58>,\n",
       " 'activation_136': <keras.layers.core.Activation at 0x7f78700df390>,\n",
       " 'activation_137': <keras.layers.core.Activation at 0x7f78700aff60>,\n",
       " 'activation_138': <keras.layers.core.Activation at 0x7f7870013c50>,\n",
       " 'activation_139': <keras.layers.core.Activation at 0x7f7858586908>,\n",
       " 'activation_140': <keras.layers.core.Activation at 0x7f78584d9a58>,\n",
       " 'activation_141': <keras.layers.core.Activation at 0x7f78584bc7b8>,\n",
       " 'activation_142': <keras.layers.core.Activation at 0x7f785841ce80>,\n",
       " 'activation_143': <keras.layers.core.Activation at 0x7f785839c630>,\n",
       " 'activation_144': <keras.layers.core.Activation at 0x7f785837fa20>,\n",
       " 'activation_145': <keras.layers.core.Activation at 0x7f78582e39e8>,\n",
       " 'activation_146': <keras.layers.core.Activation at 0x7f78582a6860>,\n",
       " 'activation_147': <keras.layers.core.Activation at 0x7f785827c860>,\n",
       " 'activation_148': <keras.layers.core.Activation at 0x7f78581ddf28>,\n",
       " 'activation_149': <keras.layers.core.Activation at 0x7f7858158da0>,\n",
       " 'activation_150': <keras.layers.core.Activation at 0x7f7858191da0>,\n",
       " 'activation_151': <keras.layers.core.Activation at 0x7f7858108470>,\n",
       " 'activation_152': <keras.layers.core.Activation at 0x7f78580d6780>,\n",
       " 'activation_153': <keras.layers.core.Activation at 0x7f7858038e48>,\n",
       " 'activation_154': <keras.layers.core.Activation at 0x7f7840204cf8>,\n",
       " 'activation_155': <keras.layers.core.Activation at 0x7f7840168ba8>,\n",
       " 'activation_156': <keras.layers.core.Activation at 0x7f78401314e0>,\n",
       " 'activation_157': <keras.layers.core.Activation at 0x7f7840102b38>,\n",
       " 'activation_158': <keras.layers.core.Activation at 0x7f78400e4a20>,\n",
       " 'activation_159': <keras.layers.core.Activation at 0x7f7840046ef0>,\n",
       " 'activation_160': <keras.layers.core.Activation at 0x7f7804232a90>,\n",
       " 'activation_161': <keras.layers.core.Activation at 0x7f7804200d68>,\n",
       " 'activation_162': <keras.layers.core.Activation at 0x7f7804178400>,\n",
       " 'activation_163': <keras.layers.core.Activation at 0x7f7804146748>,\n",
       " 'activation_164': <keras.layers.core.Activation at 0x7f78040bfb70>,\n",
       " 'activation_165': <keras.layers.core.Activation at 0x7f78040a3630>,\n",
       " 'activation_166': <keras.layers.core.Activation at 0x7f78007c0c50>,\n",
       " 'activation_167': <keras.layers.core.Activation at 0x7f78007bb400>,\n",
       " 'activation_168': <keras.layers.core.Activation at 0x7f7800775a58>,\n",
       " 'activation_169': <keras.layers.core.Activation at 0x7f78006d67b8>,\n",
       " 'activation_170': <keras.layers.core.Activation at 0x7f78006b8e80>,\n",
       " 'activation_171': <keras.layers.core.Activation at 0x7f7800636d30>,\n",
       " 'activation_172': <keras.layers.core.Activation at 0x7f780057d2e8>,\n",
       " 'activation_173': <keras.layers.core.Activation at 0x7f7800563828>,\n",
       " 'activation_174': <keras.layers.core.Activation at 0x7f78004c76a0>,\n",
       " 'activation_175': <keras.layers.core.Activation at 0x7f78004aeb38>,\n",
       " 'activation_176': <keras.layers.core.Activation at 0x7f7800479e80>,\n",
       " 'activation_177': <keras.layers.core.Activation at 0x7f78003f95f8>,\n",
       " 'activation_178': <keras.layers.core.Activation at 0x7f7800340dd8>,\n",
       " 'activation_179': <keras.layers.core.Activation at 0x7f78002c40f0>,\n",
       " 'activation_180': <keras.layers.core.Activation at 0x7f78002f5a58>,\n",
       " 'activation_181': <keras.layers.core.Activation at 0x7f780026e4a8>,\n",
       " 'activation_182': <keras.layers.core.Activation at 0x7f78001efb70>,\n",
       " 'activation_183': <keras.layers.core.Activation at 0x7f780019e390>,\n",
       " 'activation_184': <keras.layers.core.Activation at 0x7f78001068d0>,\n",
       " 'activation_185': <keras.layers.core.Activation at 0x7f7800083208>,\n",
       " 'activation_186': <keras.layers.core.Activation at 0x7f78000bb9e8>,\n",
       " 'activation_187': <keras.layers.core.Activation at 0x7f77e0fd66a0>,\n",
       " 'activation_188': <keras.layers.core.Activation at 0x7f77e0f57ef0>,\n",
       " 'activation_95': <keras.layers.core.Activation at 0x7f78bdb26eb8>,\n",
       " 'activation_96': <keras.layers.core.Activation at 0x7f787b0dddd8>,\n",
       " 'activation_97': <keras.layers.core.Activation at 0x7f78bdce29b0>,\n",
       " 'activation_98': <keras.layers.core.Activation at 0x7f78bd9c2d68>,\n",
       " 'activation_99': <keras.layers.core.Activation at 0x7f78bd972a20>,\n",
       " 'average_pooling2d_10': <keras.layers.pooling.AveragePooling2D at 0x7f78bd765ac8>,\n",
       " 'average_pooling2d_11': <keras.layers.pooling.AveragePooling2D at 0x7f78bd46aeb8>,\n",
       " 'average_pooling2d_12': <keras.layers.pooling.AveragePooling2D at 0x7f787b078f98>,\n",
       " 'average_pooling2d_13': <keras.layers.pooling.AveragePooling2D at 0x7f78701edbe0>,\n",
       " 'average_pooling2d_14': <keras.layers.pooling.AveragePooling2D at 0x7f78583b3dd8>,\n",
       " 'average_pooling2d_15': <keras.layers.pooling.AveragePooling2D at 0x7f784023aeb8>,\n",
       " 'average_pooling2d_16': <keras.layers.pooling.AveragePooling2D at 0x7f78040f5c50>,\n",
       " 'average_pooling2d_17': <keras.layers.pooling.AveragePooling2D at 0x7f7800377fd0>,\n",
       " 'average_pooling2d_18': <keras.layers.pooling.AveragePooling2D at 0x7f77e0f89a90>,\n",
       " 'batch_normalization_100': <keras.layers.normalization.BatchNormalization at 0x7f78bd8ee9e8>,\n",
       " 'batch_normalization_101': <keras.layers.normalization.BatchNormalization at 0x7f78bd908898>,\n",
       " 'batch_normalization_102': <keras.layers.normalization.BatchNormalization at 0x7f78bd869e48>,\n",
       " 'batch_normalization_103': <keras.layers.normalization.BatchNormalization at 0x7f78bd8555c0>,\n",
       " 'batch_normalization_104': <keras.layers.normalization.BatchNormalization at 0x7f78bd7b9940>,\n",
       " 'batch_normalization_105': <keras.layers.normalization.BatchNormalization at 0x7f78bd79b940>,\n",
       " 'batch_normalization_106': <keras.layers.normalization.BatchNormalization at 0x7f78bd6ade80>,\n",
       " 'batch_normalization_107': <keras.layers.normalization.BatchNormalization at 0x7f78bd6ca5f8>,\n",
       " 'batch_normalization_108': <keras.layers.normalization.BatchNormalization at 0x7f78bd62c5c0>,\n",
       " 'batch_normalization_109': <keras.layers.normalization.BatchNormalization at 0x7f78bd5f3cc0>,\n",
       " 'batch_normalization_110': <keras.layers.normalization.BatchNormalization at 0x7f78bd5789b0>,\n",
       " 'batch_normalization_111': <keras.layers.normalization.BatchNormalization at 0x7f78bd53cda0>,\n",
       " 'batch_normalization_112': <keras.layers.normalization.BatchNormalization at 0x7f78bd5226d8>,\n",
       " 'batch_normalization_113': <keras.layers.normalization.BatchNormalization at 0x7f78bd4366a0>,\n",
       " 'batch_normalization_114': <keras.layers.normalization.BatchNormalization at 0x7f78bd400a58>,\n",
       " 'batch_normalization_115': <keras.layers.normalization.BatchNormalization at 0x7f78bd3d15f8>,\n",
       " 'batch_normalization_116': <keras.layers.normalization.BatchNormalization at 0x7f78bd3348d0>,\n",
       " 'batch_normalization_117': <keras.layers.normalization.BatchNormalization at 0x7f78bd3158d0>,\n",
       " 'batch_normalization_118': <keras.layers.normalization.BatchNormalization at 0x7f78bd2deb00>,\n",
       " 'batch_normalization_119': <keras.layers.normalization.BatchNormalization at 0x7f787b0b3630>,\n",
       " 'batch_normalization_120': <keras.layers.normalization.BatchNormalization at 0x7f787b016cc0>,\n",
       " 'batch_normalization_121': <keras.layers.normalization.BatchNormalization at 0x7f7878025e10>,\n",
       " 'batch_normalization_122': <keras.layers.normalization.BatchNormalization at 0x7f787060d940>,\n",
       " 'batch_normalization_123': <keras.layers.normalization.BatchNormalization at 0x7f78705d4d30>,\n",
       " 'batch_normalization_124': <keras.layers.normalization.BatchNormalization at 0x7f78705ba668>,\n",
       " 'batch_normalization_125': <keras.layers.normalization.BatchNormalization at 0x7f78704e7a20>,\n",
       " 'batch_normalization_126': <keras.layers.normalization.BatchNormalization at 0x7f78705047b8>,\n",
       " 'batch_normalization_127': <keras.layers.normalization.BatchNormalization at 0x7f7870448b38>,\n",
       " 'batch_normalization_128': <keras.layers.normalization.BatchNormalization at 0x7f78703ccb38>,\n",
       " 'batch_normalization_129': <keras.layers.normalization.BatchNormalization at 0x7f78703909b0>,\n",
       " 'batch_normalization_130': <keras.layers.normalization.BatchNormalization at 0x7f7870376e10>,\n",
       " 'batch_normalization_131': <keras.layers.normalization.BatchNormalization at 0x7f78702e1588>,\n",
       " 'batch_normalization_132': <keras.layers.normalization.BatchNormalization at 0x7f78702a6ef0>,\n",
       " 'batch_normalization_133': <keras.layers.normalization.BatchNormalization at 0x7f7870225a58>,\n",
       " 'batch_normalization_134': <keras.layers.normalization.BatchNormalization at 0x7f7870188dd8>,\n",
       " 'batch_normalization_135': <keras.layers.normalization.BatchNormalization at 0x7f78701506d8>,\n",
       " 'batch_normalization_136': <keras.layers.normalization.BatchNormalization at 0x7f78701366d8>,\n",
       " 'batch_normalization_137': <keras.layers.normalization.BatchNormalization at 0x7f78700fd588>,\n",
       " 'batch_normalization_138': <keras.layers.normalization.BatchNormalization at 0x7f7870061f60>,\n",
       " 'batch_normalization_139': <keras.layers.normalization.BatchNormalization at 0x7f7858575ac8>,\n",
       " 'batch_normalization_140': <keras.layers.normalization.BatchNormalization at 0x7f785853bba8>,\n",
       " 'batch_normalization_141': <keras.layers.normalization.BatchNormalization at 0x7f78584a74e0>,\n",
       " 'batch_normalization_142': <keras.layers.normalization.BatchNormalization at 0x7f785848bc88>,\n",
       " 'batch_normalization_143': <keras.layers.normalization.BatchNormalization at 0x7f78583ef9e8>,\n",
       " 'batch_normalization_144': <keras.layers.normalization.BatchNormalization at 0x7f78583d1710>,\n",
       " 'batch_normalization_145': <keras.layers.normalization.BatchNormalization at 0x7f7858333860>,\n",
       " 'batch_normalization_146': <keras.layers.normalization.BatchNormalization at 0x7f78582fc6d8>,\n",
       " 'batch_normalization_147': <keras.layers.normalization.BatchNormalization at 0x7f785825fe48>,\n",
       " 'batch_normalization_148': <keras.layers.normalization.BatchNormalization at 0x7f785824a5c0>,\n",
       " 'batch_normalization_149': <keras.layers.normalization.BatchNormalization at 0x7f785820ef28>,\n",
       " 'batch_normalization_150': <keras.layers.normalization.BatchNormalization at 0x7f7858124940>,\n",
       " 'batch_normalization_151': <keras.layers.normalization.BatchNormalization at 0x7f78580d97b8>,\n",
       " 'batch_normalization_152': <keras.layers.normalization.BatchNormalization at 0x7f78580c07f0>,\n",
       " 'batch_normalization_153': <keras.layers.normalization.BatchNormalization at 0x7f78580274e0>,\n",
       " 'batch_normalization_154': <keras.layers.normalization.BatchNormalization at 0x7f784025aa90>,\n",
       " 'batch_normalization_155': <keras.layers.normalization.BatchNormalization at 0x7f78401bcb38>,\n",
       " 'batch_normalization_156': <keras.layers.normalization.BatchNormalization at 0x7f78401a0ac8>,\n",
       " 'batch_normalization_157': <keras.layers.normalization.BatchNormalization at 0x7f7840164c18>,\n",
       " 'batch_normalization_158': <keras.layers.normalization.BatchNormalization at 0x7f78400ca550>,\n",
       " 'batch_normalization_159': <keras.layers.normalization.BatchNormalization at 0x7f7840033588>,\n",
       " 'batch_normalization_160': <keras.layers.normalization.BatchNormalization at 0x7f78042a0908>,\n",
       " 'batch_normalization_161': <keras.layers.normalization.BatchNormalization at 0x7f7804214908>,\n",
       " 'batch_normalization_162': <keras.layers.normalization.BatchNormalization at 0x7f78041c9780>,\n",
       " 'batch_normalization_163': <keras.layers.normalization.BatchNormalization at 0x7f780412f7b8>,\n",
       " 'batch_normalization_164': <keras.layers.normalization.BatchNormalization at 0x7f7804115198>,\n",
       " 'batch_normalization_165': <keras.layers.normalization.BatchNormalization at 0x7f78040882e8>,\n",
       " 'batch_normalization_166': <keras.layers.normalization.BatchNormalization at 0x7f780403dc18>,\n",
       " 'batch_normalization_167': <keras.layers.normalization.BatchNormalization at 0x7f7800791ac8>,\n",
       " 'batch_normalization_168': <keras.layers.normalization.BatchNormalization at 0x7f7800756ba8>,\n",
       " 'batch_normalization_169': <keras.layers.normalization.BatchNormalization at 0x7f78006c14e0>,\n",
       " 'batch_normalization_170': <keras.layers.normalization.BatchNormalization at 0x7f78006a4518>,\n",
       " 'batch_normalization_171': <keras.layers.normalization.BatchNormalization at 0x7f7800608ac8>,\n",
       " 'batch_normalization_172': <keras.layers.normalization.BatchNormalization at 0x7f78005ccba8>,\n",
       " 'batch_normalization_173': <keras.layers.normalization.BatchNormalization at 0x7f780054f9b0>,\n",
       " 'batch_normalization_174': <keras.layers.normalization.BatchNormalization at 0x7f7800519828>,\n",
       " 'batch_normalization_175': <keras.layers.normalization.BatchNormalization at 0x7f780047e710>,\n",
       " 'batch_normalization_176': <keras.layers.normalization.BatchNormalization at 0x7f7800447a90>,\n",
       " 'batch_normalization_177': <keras.layers.normalization.BatchNormalization at 0x7f78003cd9e8>,\n",
       " 'batch_normalization_178': <keras.layers.normalization.BatchNormalization at 0x7f78003ae9e8>,\n",
       " 'batch_normalization_179': <keras.layers.normalization.BatchNormalization at 0x7f7800327fd0>,\n",
       " 'batch_normalization_180': <keras.layers.normalization.BatchNormalization at 0x7f780028b5f8>,\n",
       " 'batch_normalization_181': <keras.layers.normalization.BatchNormalization at 0x7f78002447b8>,\n",
       " 'batch_normalization_182': <keras.layers.normalization.BatchNormalization at 0x7f78002266d8>,\n",
       " 'batch_normalization_183': <keras.layers.normalization.BatchNormalization at 0x7f780018e4a8>,\n",
       " 'batch_normalization_184': <keras.layers.normalization.BatchNormalization at 0x7f7800120ba8>,\n",
       " 'batch_normalization_185': <keras.layers.normalization.BatchNormalization at 0x7f7800138400>,\n",
       " 'batch_normalization_186': <keras.layers.normalization.BatchNormalization at 0x7f780009e6d8>,\n",
       " 'batch_normalization_187': <keras.layers.normalization.BatchNormalization at 0x7f77e0fc2710>,\n",
       " 'batch_normalization_188': <keras.layers.normalization.BatchNormalization at 0x7f77e0f3c2e8>,\n",
       " 'batch_normalization_95': <keras.layers.normalization.BatchNormalization at 0x7f78bdc31cf8>,\n",
       " 'batch_normalization_96': <keras.layers.normalization.BatchNormalization at 0x7f78d49c92e8>,\n",
       " 'batch_normalization_97': <keras.layers.normalization.BatchNormalization at 0x7f78bdce1a90>,\n",
       " 'batch_normalization_98': <keras.layers.normalization.BatchNormalization at 0x7f78bd9abd30>,\n",
       " 'batch_normalization_99': <keras.layers.normalization.BatchNormalization at 0x7f78bd9e2be0>,\n",
       " 'concatenate_3': <keras.layers.merge.Concatenate at 0x7f780035ea20>,\n",
       " 'concatenate_4': <keras.layers.merge.Concatenate at 0x7f77e0f89c18>,\n",
       " 'conv2d_100': <keras.layers.convolutional.Conv2D at 0x7f78bd9a3550>,\n",
       " 'conv2d_101': <keras.layers.convolutional.Conv2D at 0x7f78bd908da0>,\n",
       " 'conv2d_102': <keras.layers.convolutional.Conv2D at 0x7f78bd8cf898>,\n",
       " 'conv2d_103': <keras.layers.convolutional.Conv2D at 0x7f78bd837d68>,\n",
       " 'conv2d_104': <keras.layers.convolutional.Conv2D at 0x7f78bd818ac8>,\n",
       " 'conv2d_105': <keras.layers.convolutional.Conv2D at 0x7f78bd77ff60>,\n",
       " 'conv2d_106': <keras.layers.convolutional.Conv2D at 0x7f78bd765780>,\n",
       " 'conv2d_107': <keras.layers.convolutional.Conv2D at 0x7f78bd6ca518>,\n",
       " 'conv2d_108': <keras.layers.convolutional.Conv2D at 0x7f78bd62ceb8>,\n",
       " 'conv2d_109': <keras.layers.convolutional.Conv2D at 0x7f78bd5f3e48>,\n",
       " 'conv2d_110': <keras.layers.convolutional.Conv2D at 0x7f78bd5d8eb8>,\n",
       " 'conv2d_111': <keras.layers.convolutional.Conv2D at 0x7f78bd5a2cf8>,\n",
       " 'conv2d_112': <keras.layers.convolutional.Conv2D at 0x7f78bd522f98>,\n",
       " 'conv2d_113': <keras.layers.convolutional.Conv2D at 0x7f78bd4883c8>,\n",
       " 'conv2d_114': <keras.layers.convolutional.Conv2D at 0x7f78bd3ed588>,\n",
       " 'conv2d_115': <keras.layers.convolutional.Conv2D at 0x7f78bd3d1ef0>,\n",
       " 'conv2d_116': <keras.layers.convolutional.Conv2D at 0x7f78bd393a58>,\n",
       " 'conv2d_117': <keras.layers.convolutional.Conv2D at 0x7f78bd2f9ef0>,\n",
       " 'conv2d_118': <keras.layers.convolutional.Conv2D at 0x7f78bd2deef0>,\n",
       " 'conv2d_119': <keras.layers.convolutional.Conv2D at 0x7f78bd2a8dd8>,\n",
       " 'conv2d_120': <keras.layers.convolutional.Conv2D at 0x7f787b016320>,\n",
       " 'conv2d_121': <keras.layers.convolutional.Conv2D at 0x7f7878025da0>,\n",
       " 'conv2d_122': <keras.layers.convolutional.Conv2D at 0x7f7870670e48>,\n",
       " 'conv2d_123': <keras.layers.convolutional.Conv2D at 0x7f787063bc88>,\n",
       " 'conv2d_124': <keras.layers.convolutional.Conv2D at 0x7f78705baf28>,\n",
       " 'conv2d_125': <keras.layers.convolutional.Conv2D at 0x7f7870521390>,\n",
       " 'conv2d_126': <keras.layers.convolutional.Conv2D at 0x7f7870504e10>,\n",
       " 'conv2d_127': <keras.layers.convolutional.Conv2D at 0x7f7870448cc0>,\n",
       " 'conv2d_128': <keras.layers.convolutional.Conv2D at 0x7f787042df98>,\n",
       " 'conv2d_129': <keras.layers.convolutional.Conv2D at 0x7f7870390d68>,\n",
       " 'conv2d_130': <keras.layers.convolutional.Conv2D at 0x7f787035b860>,\n",
       " 'conv2d_131': <keras.layers.convolutional.Conv2D at 0x7f7870342d30>,\n",
       " 'conv2d_132': <keras.layers.convolutional.Conv2D at 0x7f78702a6f60>,\n",
       " 'conv2d_133': <keras.layers.convolutional.Conv2D at 0x7f7870207c50>,\n",
       " 'conv2d_134': <keras.layers.convolutional.Conv2D at 0x7f78701ed8d0>,\n",
       " 'conv2d_135': <keras.layers.convolutional.Conv2D at 0x7f7870150710>,\n",
       " 'conv2d_136': <keras.layers.convolutional.Conv2D at 0x7f7870136fd0>,\n",
       " 'conv2d_137': <keras.layers.convolutional.Conv2D at 0x7f78700fd0b8>,\n",
       " 'conv2d_138': <keras.layers.convolutional.Conv2D at 0x7f7870061fd0>,\n",
       " 'conv2d_139': <keras.layers.convolutional.Conv2D at 0x7f7870044cc0>,\n",
       " 'conv2d_140': <keras.layers.convolutional.Conv2D at 0x7f7858521b00>,\n",
       " 'conv2d_141': <keras.layers.convolutional.Conv2D at 0x7f78584a7fd0>,\n",
       " 'conv2d_142': <keras.layers.convolutional.Conv2D at 0x7f785846ecc0>,\n",
       " 'conv2d_143': <keras.layers.convolutional.Conv2D at 0x7f7858451ef0>,\n",
       " 'conv2d_144': <keras.layers.convolutional.Conv2D at 0x7f78583b3b38>,\n",
       " 'conv2d_145': <keras.layers.convolutional.Conv2D at 0x7f785831a9e8>,\n",
       " 'conv2d_146': <keras.layers.convolutional.Conv2D at 0x7f78582fcda0>,\n",
       " 'conv2d_147': <keras.layers.convolutional.Conv2D at 0x7f78582c5898>,\n",
       " 'conv2d_148': <keras.layers.convolutional.Conv2D at 0x7f7858229d68>,\n",
       " 'conv2d_149': <keras.layers.convolutional.Conv2D at 0x7f785820ef98>,\n",
       " 'conv2d_150': <keras.layers.convolutional.Conv2D at 0x7f7858173780>,\n",
       " 'conv2d_151': <keras.layers.convolutional.Conv2D at 0x7f78580d9b70>,\n",
       " 'conv2d_152': <keras.layers.convolutional.Conv2D at 0x7f78580a3f98>,\n",
       " 'conv2d_153': <keras.layers.convolutional.Conv2D at 0x7f7858086c88>,\n",
       " 'conv2d_154': <keras.layers.convolutional.Conv2D at 0x7f784023a978>,\n",
       " 'conv2d_155': <keras.layers.convolutional.Conv2D at 0x7f784021dcc0>,\n",
       " 'conv2d_156': <keras.layers.convolutional.Conv2D at 0x7f7840180fd0>,\n",
       " 'conv2d_157': <keras.layers.convolutional.Conv2D at 0x7f784014bb70>,\n",
       " 'conv2d_158': <keras.layers.convolutional.Conv2D at 0x7f78400cae10>,\n",
       " 'conv2d_159': <keras.layers.convolutional.Conv2D at 0x7f7840095d30>,\n",
       " 'conv2d_160': <keras.layers.convolutional.Conv2D at 0x7f7804280a90>,\n",
       " 'conv2d_161': <keras.layers.convolutional.Conv2D at 0x7f7804264f98>,\n",
       " 'conv2d_162': <keras.layers.convolutional.Conv2D at 0x7f78041c9b38>,\n",
       " 'conv2d_163': <keras.layers.convolutional.Conv2D at 0x7f7804192f60>,\n",
       " 'conv2d_164': <keras.layers.convolutional.Conv2D at 0x7f7804115160>,\n",
       " 'conv2d_165': <keras.layers.convolutional.Conv2D at 0x7f78040daf98>,\n",
       " 'conv2d_166': <keras.layers.convolutional.Conv2D at 0x7f780403dfd0>,\n",
       " 'conv2d_167': <keras.layers.convolutional.Conv2D at 0x7f78007f2cc0>,\n",
       " 'conv2d_168': <keras.layers.convolutional.Conv2D at 0x7f78007a0940>,\n",
       " 'conv2d_169': <keras.layers.convolutional.Conv2D at 0x7f78006c1fd0>,\n",
       " 'conv2d_170': <keras.layers.convolutional.Conv2D at 0x7f7800686cc0>,\n",
       " 'conv2d_171': <keras.layers.convolutional.Conv2D at 0x7f780061cc88>,\n",
       " 'conv2d_172': <keras.layers.convolutional.Conv2D at 0x7f78005cc9b0>,\n",
       " 'conv2d_173': <keras.layers.convolutional.Conv2D at 0x7f7800596e48>,\n",
       " 'conv2d_174': <keras.layers.convolutional.Conv2D at 0x7f7800519be0>,\n",
       " 'conv2d_175': <keras.layers.convolutional.Conv2D at 0x7f78004e2ef0>,\n",
       " 'conv2d_176': <keras.layers.convolutional.Conv2D at 0x7f7800466518>,\n",
       " 'conv2d_177': <keras.layers.convolutional.Conv2D at 0x7f780042def0>,\n",
       " 'conv2d_178': <keras.layers.convolutional.Conv2D at 0x7f7800394dd8>,\n",
       " 'conv2d_179': <keras.layers.convolutional.Conv2D at 0x7f7800314438>,\n",
       " 'conv2d_180': <keras.layers.convolutional.Conv2D at 0x7f78002e1780>,\n",
       " 'conv2d_181': <keras.layers.convolutional.Conv2D at 0x7f7800244ba8>,\n",
       " 'conv2d_182': <keras.layers.convolutional.Conv2D at 0x7f78002096a0>,\n",
       " 'conv2d_183': <keras.layers.convolutional.Conv2D at 0x7f780018ed68>,\n",
       " 'conv2d_184': <keras.layers.convolutional.Conv2D at 0x7f78001528d0>,\n",
       " 'conv2d_185': <keras.layers.convolutional.Conv2D at 0x7f7800138da0>,\n",
       " 'conv2d_186': <keras.layers.convolutional.Conv2D at 0x7f780009efd0>,\n",
       " 'conv2d_187': <keras.layers.convolutional.Conv2D at 0x7f7800068eb8>,\n",
       " 'conv2d_188': <keras.layers.convolutional.Conv2D at 0x7f77e0fa8ac8>,\n",
       " 'conv2d_95': <keras.layers.convolutional.Conv2D at 0x7f78bdc31d30>,\n",
       " 'conv2d_96': <keras.layers.convolutional.Conv2D at 0x7f787bae3f28>,\n",
       " 'conv2d_97': <keras.layers.convolutional.Conv2D at 0x7f78bdce18d0>,\n",
       " 'conv2d_98': <keras.layers.convolutional.Conv2D at 0x7f78bdae48d0>,\n",
       " 'conv2d_99': <keras.layers.convolutional.Conv2D at 0x7f78bd9c2dd8>,\n",
       " 'input_2': <keras.engine.topology.InputLayer at 0x7f78bdc311d0>,\n",
       " 'max_pooling2d_5': <keras.layers.pooling.MaxPooling2D at 0x7f78bdae4e10>,\n",
       " 'max_pooling2d_6': <keras.layers.pooling.MaxPooling2D at 0x7f78bd9a3dd8>,\n",
       " 'max_pooling2d_7': <keras.layers.pooling.MaxPooling2D at 0x7f7870582e48>,\n",
       " 'max_pooling2d_8': <keras.layers.pooling.MaxPooling2D at 0x7f780066bef0>,\n",
       " 'mixed0': <keras.layers.merge.Concatenate at 0x7f78bd6caef0>,\n",
       " 'mixed1': <keras.layers.merge.Concatenate at 0x7f78bd3edef0>,\n",
       " 'mixed10': <keras.layers.merge.Concatenate at 0x7f77e0f6fbe0>,\n",
       " 'mixed2': <keras.layers.merge.Concatenate at 0x7f7878025e48>,\n",
       " 'mixed3': <keras.layers.merge.Concatenate at 0x7f7870521358>,\n",
       " 'mixed4': <keras.layers.merge.Concatenate at 0x7f7870150b00>,\n",
       " 'mixed5': <keras.layers.merge.Concatenate at 0x7f785831ada0>,\n",
       " 'mixed6': <keras.layers.merge.Concatenate at 0x7f784021dcf8>,\n",
       " 'mixed7': <keras.layers.merge.Concatenate at 0x7f78040dafd0>,\n",
       " 'mixed8': <keras.layers.merge.Concatenate at 0x7f780066b9b0>,\n",
       " 'mixed9': <keras.layers.merge.Concatenate at 0x7f78002e1ba8>,\n",
       " 'mixed9_0': <keras.layers.merge.Concatenate at 0x7f78004e26d8>,\n",
       " 'mixed9_1': <keras.layers.merge.Concatenate at 0x7f78001b6a90>}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as in making visible the layers activation in chapter 5, we define a gradient ascent process.\n",
    "\n",
    "# This holds our generated image\n",
    "dream = model.input\n",
    "\n",
    "# Compute the gradients of the dream with regard to the loss.\n",
    "grads = K.gradients(loss, dream)[0]\n",
    "\n",
    "# Normalize gradients --> important trick\n",
    "grads /= K.maximum(K.mean(K.abs(grads)), 1e-7)\n",
    "\n",
    "# Set up function to retrieve the value\n",
    "# of the loss and gradients given an input image.\n",
    "outputs = [loss, grads]\n",
    "fetch_loss_and_grads = K.function([dream], outputs)\n",
    "\n",
    "def eval_loss_and_grads(x):\n",
    "    outs = fetch_loss_and_grads([x])\n",
    "    loss_value = outs[0]\n",
    "    grad_values = outs[1]\n",
    "    return loss_value, grad_values\n",
    "\n",
    "def gradient_ascent(x, iterations, step, max_loss=None):\n",
    "    for i in range(iterations):\n",
    "        loss_value, grad_values = eval_loss_and_grads(x)\n",
    "        if max_loss is not None and loss_value > max_loss:\n",
    "            break\n",
    "        print('...Loss value at', i, ':', loss_value)\n",
    "        x += step * grad_values\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining auxiliary numpy functions for the deepdream algorithm\n",
    "\n",
    "import scipy\n",
    "import imageio\n",
    "import os\n",
    "from keras.preprocessing import image\n",
    "\n",
    "def resize_img(img, size):\n",
    "    img = np.copy(img)\n",
    "    factors = (1,\n",
    "               float(size[0]) / img.shape[1],\n",
    "               float(size[1]) / img.shape[2],\n",
    "               1)\n",
    "    return scipy.ndimage.zoom(img, factors, order=1)\n",
    "\n",
    "\n",
    "def save_img(img, fname):\n",
    "    pil_img = deprocess_image(np.copy(img))\n",
    "    imageio.imwrite(fname, pil_img) \n",
    "    \n",
    "def preprocess_image(image_path):\n",
    "    # Util function to open, resize and format pictures\n",
    "    # into appropriate tensors.\n",
    "    img = image.load_img(image_path)\n",
    "    img = image.img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = inception_v3.preprocess_input(img)\n",
    "    return img\n",
    "\n",
    "\n",
    "def deprocess_image(x):\n",
    "    # Util function to convert a tensor into a valid image.\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        x = x.reshape((3, x.shape[2], x.shape[3]))\n",
    "        x = x.transpose((1, 2, 0))\n",
    "    else:\n",
    "        x = x.reshape((x.shape[1], x.shape[2], 3))\n",
    "    x /= 2.\n",
    "    x += 0.5\n",
    "    x *= 255.\n",
    "    x = np.clip(x, 0, 255).astype('uint8')\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image shape (182, 136)\n",
      "...Loss value at 0 : 0.0\n",
      "...Loss value at 1 : 0.0\n",
      "...Loss value at 2 : 0.0\n",
      "...Loss value at 3 : 0.0\n",
      "...Loss value at 4 : 0.0\n",
      "...Loss value at 5 : 0.0\n",
      "...Loss value at 6 : 0.0\n",
      "...Loss value at 7 : 0.0\n",
      "...Loss value at 8 : 0.0\n",
      "...Loss value at 9 : 0.0\n",
      "...Loss value at 10 : 0.0\n",
      "...Loss value at 11 : 0.0\n",
      "...Loss value at 12 : 0.0\n",
      "...Loss value at 13 : 0.0\n",
      "...Loss value at 14 : 0.0\n",
      "...Loss value at 15 : 0.0\n",
      "...Loss value at 16 : 0.0\n",
      "...Loss value at 17 : 0.0\n",
      "...Loss value at 18 : 0.0\n",
      "...Loss value at 19 : 0.0\n",
      "...Loss value at 20 : 0.0\n",
      "...Loss value at 21 : 0.0\n",
      "...Loss value at 22 : 0.0\n",
      "...Loss value at 23 : 0.0\n",
      "...Loss value at 24 : 0.0\n",
      "Processing image shape (254, 191)\n",
      "...Loss value at 0 : 0.0\n",
      "...Loss value at 1 : 0.0\n",
      "...Loss value at 2 : 0.0\n",
      "...Loss value at 3 : 0.0\n",
      "...Loss value at 4 : 0.0\n",
      "...Loss value at 5 : 0.0\n",
      "...Loss value at 6 : 0.0\n",
      "...Loss value at 7 : 0.0\n",
      "...Loss value at 8 : 0.0\n",
      "...Loss value at 9 : 0.0\n",
      "...Loss value at 10 : 0.0\n",
      "...Loss value at 11 : 0.0\n",
      "...Loss value at 12 : 0.0\n",
      "...Loss value at 13 : 0.0\n",
      "...Loss value at 14 : 0.0\n",
      "...Loss value at 15 : 0.0\n",
      "...Loss value at 16 : 0.0\n",
      "...Loss value at 17 : 0.0\n",
      "...Loss value at 18 : 0.0\n",
      "...Loss value at 19 : 0.0\n",
      "...Loss value at 20 : 0.0\n",
      "...Loss value at 21 : 0.0\n",
      "...Loss value at 22 : 0.0\n",
      "...Loss value at 23 : 0.0\n",
      "...Loss value at 24 : 0.0\n",
      "Processing image shape (356, 267)\n",
      "...Loss value at 0 : 0.15900142\n",
      "...Loss value at 1 : 0.35538605\n",
      "...Loss value at 2 : 0.6784317\n",
      "...Loss value at 3 : 1.0421685\n",
      "...Loss value at 4 : 1.3064162\n",
      "...Loss value at 5 : 1.5079645\n",
      "...Loss value at 6 : 1.9900991\n",
      "...Loss value at 7 : 2.8690681\n",
      "...Loss value at 8 : 3.1281707\n",
      "...Loss value at 9 : 3.8061128\n",
      "...Loss value at 10 : 5.008255\n",
      "...Loss value at 11 : 5.850168\n",
      "...Loss value at 12 : 6.5985947\n",
      "...Loss value at 13 : 8.534949\n",
      "...Loss value at 14 : 8.112809\n",
      "...Loss value at 15 : 9.220405\n",
      "...Loss value at 16 : 9.776011\n",
      "...Loss value at 17 : 9.669835\n",
      "Processing image shape (499, 374)\n",
      "...Loss value at 0 : 0.27301365\n",
      "...Loss value at 1 : 1.0583668\n",
      "...Loss value at 2 : 1.4499078\n",
      "...Loss value at 3 : 1.929655\n",
      "...Loss value at 4 : 2.7898765\n",
      "...Loss value at 5 : 3.5857682\n",
      "...Loss value at 6 : 3.6418424\n",
      "...Loss value at 7 : 5.687272\n",
      "...Loss value at 8 : 7.760005\n",
      "...Loss value at 9 : 8.624098\n",
      "...Loss value at 10 : 9.633033\n",
      "Processing image shape (699, 524)\n",
      "...Loss value at 0 : 0.39830467\n",
      "...Loss value at 1 : 0.8029255\n",
      "...Loss value at 2 : 1.1954958\n",
      "...Loss value at 3 : 1.6561234\n",
      "...Loss value at 4 : 2.4029377\n",
      "...Loss value at 5 : 3.843068\n",
      "...Loss value at 6 : 3.1879733\n",
      "...Loss value at 7 : 4.9788485\n",
      "...Loss value at 8 : 4.238832\n",
      "...Loss value at 9 : 5.979707\n",
      "...Loss value at 10 : 8.846477\n",
      "Processing image shape (979, 734)\n",
      "...Loss value at 0 : 0.53488463\n",
      "...Loss value at 1 : 1.1157554\n",
      "...Loss value at 2 : 1.1501383\n",
      "...Loss value at 3 : 2.2613566\n",
      "...Loss value at 4 : 2.1206686\n",
      "...Loss value at 5 : 3.6604376\n",
      "...Loss value at 6 : 3.6042442\n",
      "...Loss value at 7 : 5.213373\n",
      "...Loss value at 8 : 4.771779\n",
      "...Loss value at 9 : 7.052923\n",
      "...Loss value at 10 : 8.0914\n",
      "...Loss value at 11 : 8.455001\n",
      "Processing image shape (1371, 1028)\n",
      "...Loss value at 0 : 0.58346564\n",
      "...Loss value at 1 : 1.1239587\n",
      "...Loss value at 2 : 1.2416092\n",
      "...Loss value at 3 : 2.678567\n",
      "...Loss value at 4 : 2.4395013\n",
      "...Loss value at 5 : 3.5297444\n",
      "...Loss value at 6 : 4.60829\n",
      "...Loss value at 7 : 5.539004\n",
      "...Loss value at 8 : 5.2398334\n",
      "...Loss value at 9 : 6.633599\n",
      "...Loss value at 10 : 7.8127933\n",
      "...Loss value at 11 : 8.582548\n",
      "...Loss value at 12 : 9.018782\n",
      "Processing image shape (1920, 1440)\n",
      "...Loss value at 0 : 0.726843\n",
      "...Loss value at 1 : 1.5305333\n",
      "...Loss value at 2 : 1.9183664\n",
      "...Loss value at 3 : 2.5324621\n",
      "...Loss value at 4 : 2.8041503\n",
      "...Loss value at 5 : 3.941434\n",
      "...Loss value at 6 : 4.641929\n",
      "...Loss value at 7 : 5.934883\n",
      "...Loss value at 8 : 6.2329435\n",
      "...Loss value at 9 : 7.5974116\n",
      "...Loss value at 10 : 9.337482\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/joel/generative_dl/images/final_dream.png'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We start by defining a list of scales at which to process the image.\n",
    "# Then we process a small image with the deepdream algorithm, scale it up by 40% and go on like this.\n",
    "\n",
    "import numpy as np\n",
    "import shutil\n",
    "\n",
    "# Playing with these hyperparameters will also allow you to achieve new effects\n",
    "\n",
    "step = 0.01  # Gradient ascent step size\n",
    "num_octave = 6  # Number of scales at which to run gradient ascent\n",
    "octave_scale = 1.4  # Size ratio between scales\n",
    "iterations = 25  # Number of ascent steps per scale\n",
    "\n",
    "# If our loss gets larger than 10,\n",
    "# we will interrupt the gradient ascent process, to avoid ugly artifacts\n",
    "max_loss = 10.\n",
    "\n",
    "# Fill this to the path to the image you want to use\n",
    "base_image_path = '/home/joel/generative_dl/miri_emi.jpeg'\n",
    "\n",
    "# Load the image into a Numpy array\n",
    "img = preprocess_image(base_image_path)\n",
    "\n",
    "# We prepare a list of shape tuples\n",
    "# defining the different scales at which we will run gradient ascent\n",
    "original_shape = img.shape[1:3]\n",
    "successive_shapes = [original_shape]\n",
    "for i in range(1, num_octave):\n",
    "    shape = tuple([int(dim / (octave_scale ** i)) for dim in original_shape])\n",
    "    successive_shapes.append(shape)\n",
    "\n",
    "# Reverse list of shapes, so that they are in increasing order\n",
    "successive_shapes = successive_shapes[::-1]\n",
    "\n",
    "# Resize the Numpy array of the image to our smallest scale\n",
    "original_img = np.copy(img)\n",
    "shrunk_original_img = resize_img(img, successive_shapes[0])\n",
    "\n",
    "for shape in successive_shapes:\n",
    "    print('Processing image shape', shape)\n",
    "    img = resize_img(img, shape)\n",
    "    img = gradient_ascent(img,\n",
    "                          iterations=iterations,\n",
    "                          step=step,\n",
    "                          max_loss=max_loss)\n",
    "    upscaled_shrunk_original_img = resize_img(shrunk_original_img, shape)\n",
    "    same_size_original = resize_img(original_img, shape)\n",
    "    lost_detail = same_size_original - upscaled_shrunk_original_img\n",
    "\n",
    "    img += lost_detail\n",
    "    shrunk_original_img = resize_img(original_img, shape)\n",
    "    save_img(img, fname='dream_at_scale_' + str(shape) + '.png')\n",
    "    shutil.move('/home/joel/generative_dl/dream_at_scale_' + str(shape) + '.png', '/home/joel/generative_dl/images')\n",
    "    \n",
    "save_img(img, fname='final_dream.png')\n",
    "\n",
    "shutil.move('/home/joel/generative_dl/final_dream.png', '/home/joel/generative_dl/images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
